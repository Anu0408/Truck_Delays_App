{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: hopsworks in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (3.7.0)\n",
      "Requirement already satisfied: hsfs<3.8.0,>=3.7.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.7.7)\n",
      "Requirement already satisfied: hsml<3.8.0,>=3.7.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hopsworks) (3.7.1)\n",
      "Requirement already satisfied: pyhumps==1.6.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hopsworks) (1.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hopsworks) (2.32.3)\n",
      "Requirement already satisfied: furl in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hopsworks) (2.1.3)\n",
      "Requirement already satisfied: boto3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hopsworks) (1.35.22)\n",
      "Requirement already satisfied: pyjks in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hopsworks) (20.0.0)\n",
      "Requirement already satisfied: mock in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hopsworks) (5.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hopsworks) (4.66.5)\n",
      "Requirement already satisfied: pandas<2.2.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.1.4)\n",
      "Requirement already satisfied: numpy<2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.26.4)\n",
      "Requirement already satisfied: avro==1.11.3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.11.3)\n",
      "Requirement already satisfied: sqlalchemy<=1.4.48 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.4.48)\n",
      "Requirement already satisfied: PyMySQL[rsa] in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.1.1)\n",
      "Requirement already satisfied: great-expectations==0.18.12 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.18.12)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (5.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2024.9.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.3.4)\n",
      "Requirement already satisfied: aiomysql in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.2.0)\n",
      "Requirement already satisfied: opensearch-py<=2.4.2,>=1.1.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.4.2)\n",
      "Requirement already satisfied: altair<5.0.0,>=4.2.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.2.2)\n",
      "Requirement already satisfied: Click>=7.1.2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (8.1.7)\n",
      "Requirement already satisfied: colorama>=0.4.3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.4.6)\n",
      "Requirement already satisfied: cryptography>=3.2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (43.0.1)\n",
      "Requirement already satisfied: Ipython>=7.16.3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (8.27.0)\n",
      "Requirement already satisfied: ipywidgets>=7.5.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (8.1.5)\n",
      "Requirement already satisfied: jinja2>=2.10 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.1.4)\n",
      "Requirement already satisfied: jsonpatch>=1.22 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.33)\n",
      "Requirement already satisfied: jsonschema>=2.5.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.23.0)\n",
      "Requirement already satisfied: makefun<2,>=1.7.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.15.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.7.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.22.0)\n",
      "Requirement already satisfied: mistune>=0.8.4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.0.2)\n",
      "Requirement already satisfied: nbformat>=5.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (5.10.4)\n",
      "Requirement already satisfied: notebook>=6.4.10 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (7.2.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (24.1)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.9.2)\n",
      "Requirement already satisfied: pyparsing>=2.4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2021.3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2024.1)\n",
      "Requirement already satisfied: ruamel.yaml<0.17.18,>=0.16 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.17.17)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.2.2)\n",
      "Requirement already satisfied: pyhopshive[thrift] in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.6.4.1.dev0)\n",
      "Requirement already satisfied: pyarrow>=10.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs[python]<3.8.0,>=3.7.0->hopsworks) (17.0.0)\n",
      "Requirement already satisfied: confluent-kafka<=2.3.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.3.0)\n",
      "Requirement already satisfied: fastavro<=1.8.4,>=1.4.11 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->hopsworks) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->hopsworks) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests->hopsworks) (2024.8.30)\n",
      "Requirement already satisfied: botocore<1.36.0,>=1.35.22 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from boto3->hopsworks) (1.35.22)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from boto3->hopsworks) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from boto3->hopsworks) (0.10.2)\n",
      "Requirement already satisfied: six>=1.8.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from furl->hopsworks) (1.16.0)\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from furl->hopsworks) (1.0.1)\n",
      "Requirement already satisfied: javaobj-py3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pyjks->hopsworks) (0.4.4)\n",
      "Requirement already satisfied: pyasn1>=0.3.5 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pyjks->hopsworks) (0.6.1)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pyjks->hopsworks) (0.4.1)\n",
      "Requirement already satisfied: pycryptodomex in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pyjks->hopsworks) (3.20.0)\n",
      "Requirement already satisfied: twofish in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pyjks->hopsworks) (0.3.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas<2.2.0->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2024.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sqlalchemy<=1.4.48->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.1.0)\n",
      "Requirement already satisfied: future in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pyhopshive[thrift]; extra == \"python\"->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.0.0)\n",
      "Requirement already satisfied: thrift>=0.10.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pyhopshive[thrift]; extra == \"python\"->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.20.0)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from altair<5.0.0,>=4.2.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.4)\n",
      "Requirement already satisfied: toolz in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from altair<5.0.0,>=4.2.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from cryptography>=3.2->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.17.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets>=7.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.2.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets>=7.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipywidgets>=7.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.0.13)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jinja2>=2.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonpatch>=1.22->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (3.0.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=2.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=2.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=2.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema>=2.5.1->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.20.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbformat>=5.0->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.20.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbformat>=5.0->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (5.7.2)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.2.5)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (6.4.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic>=1.9.2->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pydantic>=1.9.2->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.23.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from cffi>=1.12->cryptography>=3.2->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jedi>=0.16->Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.8.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.0->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.3.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.0->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (306)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.4.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (8.6.2)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (7.16.4)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.20.0)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.0.13)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (26.2.0)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.27.2)\n",
      "Requirement already satisfied: ipykernel>=6.5.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (6.29.5)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.2.5)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (74.1.2)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.16.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.9.25)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack-data->Ipython>=7.16.3->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.2.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (21.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.14.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.8.5)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel>=6.5.0->jupyterlab<4.3,>=4.2.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (6.0.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (6.0.2)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.3.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.3.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (0.5.1)\n",
      "Requirement already satisfied: fqdn in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (20.11.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (24.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.6)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook>=6.4.10->great-expectations==0.18.12->hsfs<3.8.0,>=3.7.0->hsfs[python]<3.8.0,>=3.7.0->hopsworks) (2.9.0.20240821)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1104021\n",
      "2024-10-16 14:30:28,486 WARNING: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "\n",
      "2024-10-16 14:30:28,488 WARNING: using legacy validation callback\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# Initialize connection to Hopsworks using API key\n",
    "project = hopsworks.login(\n",
    "    api_key_value=\"8ViXMBkcrCAUFm4Y.PEDm3J6NPoMDtf2L7MpnYsCdElsDMCPRr1RI3vbPtLnjogWE1f6hdKOoxpQbxrM0\"\n",
    ")\n",
    "\n",
    "# Get the feature store for the project\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Create a new feature store (if needed)\n",
    "# You can specify the name and other parameters if required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# import hopsworks\n",
    "# import pandas as pd\n",
    "# project = hopsworks.login()\n",
    "\n",
    "# fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_weather_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_city_weather.csv')\n",
    "drivers_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_drivers.csv')\n",
    "routes_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_routes.csv')\n",
    "routes_weather_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_routes_weather.csv')\n",
    "traffic_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_traffic.csv')\n",
    "trucks_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_trucks.csv')\n",
    "truck_schedule_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_truck_schedule.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_weather_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_city_weather.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51834, 18)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                int64\n",
       "id                   int64\n",
       "city_id             object\n",
       "date                object\n",
       "hour                 int64\n",
       "temp                 int64\n",
       "wind_speed           int64\n",
       "description         object\n",
       "precip             float64\n",
       "humidity             int64\n",
       "visibility           int64\n",
       "pressure             int64\n",
       "chanceofrain         int64\n",
       "chanceoffog          int64\n",
       "chanceofsnow         int64\n",
       "chanceofthunder      int64\n",
       "date_time           object\n",
       "event_date          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the event_time feature for city_weather_df\n",
    "# city_weather_df['event_time'] = pd.to_datetime('2024-09-19')\n",
    "\n",
    "# # Display the updated city_weather_df\n",
    "# print(city_weather_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                int64\n",
       "id                   int64\n",
       "city_id             object\n",
       "date                object\n",
       "hour                 int64\n",
       "temp                 int64\n",
       "wind_speed           int64\n",
       "description         object\n",
       "precip             float64\n",
       "humidity             int64\n",
       "visibility           int64\n",
       "pressure             int64\n",
       "chanceofrain         int64\n",
       "chanceoffog          int64\n",
       "chanceofsnow         int64\n",
       "chanceofthunder      int64\n",
       "date_time           object\n",
       "event_date          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Drop the 'id' column if it's not needed in the feature group\n",
    "# if 'id' in city_weather_df.columns:\n",
    "#     city_weather_df = city_weather_df.drop(columns=['id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime64[ns]\n",
      "datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming city_weather_df is your DataFrame\n",
    "city_weather_df['date_time'] = pd.to_datetime(city_weather_df['date_time'])\n",
    "city_weather_df['event_date'] = pd.to_datetime(city_weather_df['event_date'])\n",
    "# Verify the conversion\n",
    "print(city_weather_df['date_time'].dtype)  # This should now show 'datetime64[ns]'\n",
    "print(city_weather_df['event_date'].dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                       int64\n",
       "id                          int64\n",
       "city_id                    object\n",
       "date                       object\n",
       "hour                        int64\n",
       "temp                        int64\n",
       "wind_speed                  int64\n",
       "description                object\n",
       "precip                    float64\n",
       "humidity                    int64\n",
       "visibility                  int64\n",
       "pressure                    int64\n",
       "chanceofrain                int64\n",
       "chanceoffog                 int64\n",
       "chanceofsnow                int64\n",
       "chanceofthunder             int64\n",
       "date_time          datetime64[ns]\n",
       "event_date         datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_weather_df['event_date'] = pd.to_datetime(city_weather_df['event_date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index              0\n",
      "id                 0\n",
      "city_id            0\n",
      "date               0\n",
      "hour               0\n",
      "temp               0\n",
      "wind_speed         0\n",
      "description        0\n",
      "precip             0\n",
      "humidity           0\n",
      "visibility         0\n",
      "pressure           0\n",
      "chanceofrain       0\n",
      "chanceoffog        0\n",
      "chanceofsnow       0\n",
      "chanceofthunder    0\n",
      "date_time          0\n",
      "event_date         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(city_weather_df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_weather_df['date_time'] = city_weather_df['date_time'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_weather_fg = fs.create_feature_group(\n",
    "    name=\"city_weather\",\n",
    "    version=1,\n",
    "    description=\"City weather data feature group\",\n",
    "    primary_key=[\"index\"],  # Ensure 'index' exists and is unique\n",
    "    event_time=\"event_date\",  # Ensure 'event_date' is in timestamp/date format\n",
    "    online_enabled=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02be6ab8eee04c60a6760c12536cc423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/51834 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: city_weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1104021/jobs/named/city_weather_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x267129a7bf0>, None)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the existing feature group\n",
    "city_weather_fg = fs.get_feature_group(name=\"city_weather\", version=1)\n",
    "\n",
    "# Insert data into the feature group\n",
    "city_weather_fg.insert(city_weather_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51834, 18)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature descriptions for city_weather_df\n",
    "feature_descriptions_city_weather = [\n",
    "    {\"name\": \"city_id\", \"description\": \"unique identification for each city\"},\n",
    "    {\"name\": \"date\", \"description\": \"date of the weather observation\"},\n",
    "    {\"name\": \"hour\", \"description\": \"hour of the day when the observation was made\"},\n",
    "    {\"name\": \"temp\", \"description\": \"temperature recorded in degrees Fahrenheit\"},\n",
    "    {\"name\": \"wind_speed\", \"description\": \"speed of the wind in miles per hour\"},\n",
    "    {\"name\": \"description\", \"description\": \"weather condition description (e.g., light snow)\"},\n",
    "    {\"name\": \"precip\", \"description\": \"amount of precipitation in inches\"},\n",
    "    {\"name\": \"humidity\", \"description\": \"percentage of humidity in the air\"},\n",
    "    {\"name\": \"visibility\", \"description\": \"visibility distance in miles\"},\n",
    "    {\"name\": \"pressure\", \"description\": \"atmospheric pressure in hPa\"},\n",
    "    {\"name\": \"chanceofrain\", \"description\": \"probability of rain occurring, as a percentage\"},\n",
    "    {\"name\": \"chanceoffog\", \"description\": \"probability of fog occurring, as a percentage\"},\n",
    "    {\"name\": \"chanceofsnow\", \"description\": \"probability of snow occurring, as a percentage\"},\n",
    "    {\"name\": \"chanceofthunder\", \"description\": \"probability of thunder occurring, as a percentage\"},\n",
    "    {\"name\": \"date_time\", \"description\": \"datetime of the observation\"},\n",
    "    {\"name\": \"event_date\", \"description\": \"event date related to the observation\"}\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature group descriptions updated!\n"
     ]
    }
   ],
   "source": [
    "# Update feature group descriptions for city_weather_df\n",
    "for desc in feature_descriptions_city_weather:\n",
    "    city_weather_fg.update_feature_description(desc[\"name\"], desc[\"description\"])\n",
    "print(\" Feature group descriptions updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Enable and configure statistics for the city_weather_fg feature group\n",
    "city_weather_fg.statistics_config = {\n",
    "    \"enabled\": True,        # Enable statistics calculation\n",
    "    \"histograms\": True,     # Include histograms in the statistics\n",
    "    \"correlations\": True    # Include correlations in the statistics\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x267121e09e0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Step 2: Update the statistics configuration for city_weather_fg\n",
    "city_weather_fg.update_statistics_config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Statistics configured and computed for city_weather_fg!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Compute statistics for the city_weather_fg feature group\n",
    "city_weather_fg.update_statistics_config()\n",
    "\n",
    "print(\" Statistics configured and computed for city_weather_fg!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drivers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame\n",
    "drivers_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_drivers.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                  int64\n",
       "driver_id             object\n",
       "name                  object\n",
       "gender                object\n",
       "age                    int64\n",
       "experience             int64\n",
       "driving_style         object\n",
       "ratings                int64\n",
       "vehicle_no             int64\n",
       "average_speed_mph    float64\n",
       "event_date            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index   driver_id               name gender  age  experience driving_style  \\\n",
      "0      1  d9f30553-6       Daniel Marks   male   47           5     proactive   \n",
      "1      2  82de7bb8-2      Clifford Carr   male   47          14     proactive   \n",
      "2      3  7e789842-4  Terry Faulkner MD   male   41           9  conservative   \n",
      "3      4  b2555587-8     Brendan Jacobs   male   44          10     proactive   \n",
      "4      5  b2e58421-d      Vincent Davis   male   41          10     proactive   \n",
      "\n",
      "   ratings  vehicle_no  average_speed_mph event_date  \n",
      "0        7    42302347              62.22 2024-10-16  \n",
      "1        4    27867488              60.89 2024-10-16  \n",
      "2        2    13927774              53.67 2024-10-16  \n",
      "3        2    69577118              59.82 2024-10-16  \n",
      "4        7    28650047              62.65 2024-10-16  \n",
      "index                         int64\n",
      "driver_id                    object\n",
      "name                         object\n",
      "gender                       object\n",
      "age                           int64\n",
      "experience                    int64\n",
      "driving_style                object\n",
      "ratings                       int64\n",
      "vehicle_no                    int64\n",
      "average_speed_mph           float64\n",
      "event_date           datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Adding event_date column with current date\n",
    "today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "drivers_df['event_date'] = pd.to_datetime(today_date)\n",
    "\n",
    "# Print the DataFrame and its data types\n",
    "print(drivers_df.head())\n",
    "print(drivers_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the existing feature group\n",
    "#drivers_fg.delete()\n",
    "\n",
    "# Create a new feature group with the required schema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert vehicle_no to float64\n",
    "drivers_df['vehicle_no'] = drivers_df['vehicle_no'].astype('float64')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the original DataFrame\n",
    "duplicates = drivers_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "drivers_df = drivers_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature group with the required schema\n",
    "drivers_fg = fs.get_or_create_feature_group(\n",
    "    name=\"drivers\",\n",
    "    version=1,\n",
    "    description=\"features from drivers\",\n",
    "    online_enabled=False,\n",
    "    primary_key=['index'],\n",
    "    event_time='event_date'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the original DataFrame\n",
    "duplicates = drivers_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Remove duplicates\n",
    "drivers_df = drivers_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ee45ec14c14dbc8c0610f2f1e78cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1209 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: drivers_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1104021/jobs/named/drivers_1_offline_fg_materialization/executions\n",
      " Done!\n"
     ]
    }
   ],
   "source": [
    "# Insert the DataFrame into the feature group with overwrite=True\n",
    "drivers_fg.insert(drivers_df, write_options={\"overwrite\": True})\n",
    "print(' Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1209, 11)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e14376cc66745b8b1228ed85c15bef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1209 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: drivers_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1104021/jobs/named/drivers_1_offline_fg_materialization/executions\n",
      " Done!\n"
     ]
    }
   ],
   "source": [
    "# Insert the DataFrame into the newly created feature group\n",
    "drivers_fg.insert(drivers_df)\n",
    "print(' Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates in the original DataFrame\n",
    "duplicates = drivers_df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Remove duplicates\n",
    "drivers_df = drivers_df.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature descriptions for the drivers feature group\n",
    "feature_descriptions_drivers = [\n",
    "    {\"name\": \"driver_id\", \"description\": \"Unique identification for each driver\"},\n",
    "    {\"name\": \"name\", \"description\": \"Name of the truck driver\"},\n",
    "    {\"name\": \"gender\", \"description\": \"Gender of the truck driver\"},\n",
    "    {\"name\": \"age\", \"description\": \"Age of the truck driver\"},\n",
    "    {\"name\": \"experience\", \"description\": \"Experience of the truck driver in years\"},\n",
    "    {\"name\": \"driving_style\", \"description\": \"Driving style of the truck driver, conservative or proactive\"},\n",
    "    {\"name\": \"ratings\", \"description\": \"Average rating of the truck driver on a scale of 1 to 5\"},\n",
    "    {\"name\": \"vehicle_no\", \"description\": \"The number of the drivers truck\"},\n",
    "    {\"name\": \"average_speed_mph\", \"description\": \"Average speed of the truck driver in miles per hour\"},\n",
    "    {\"name\": \"event_date\", \"description\": \"Event date for the driver's data\"}\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature group descriptions updated!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Update feature descriptions in the drivers feature group\n",
    "for desc in feature_descriptions_drivers:\n",
    "    drivers_fg.update_feature_description(desc[\"name\"], desc[\"description\"])\n",
    "print(\" Feature group descriptions updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure statistics for the feature group\n",
    "drivers_fg.statistics_config = {\n",
    "    \"enabled\": True,        # Enable statistics calculation\n",
    "    \"histograms\": True,     # Include histograms in the statistics\n",
    "    \"correlations\": True    # Include correlations in the statistics\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x16632c954c0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Update the statistics configuration for the feature group\n",
    "drivers_fg.update_statistics_config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Statistics configured and computed for drivers_fg!\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics for the feature group\n",
    "drivers_fg.update_statistics_config()\n",
    "print(\" Statistics configured and computed for drivers_fg!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame\n",
    "routes_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_routes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index               int64\n",
       "id                  int64\n",
       "route_id           object\n",
       "origin_id          object\n",
       "destination_id     object\n",
       "distance          float64\n",
       "average_hours     float64\n",
       "event_date         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  id    route_id   origin_id destination_id  distance  average_hours  \\\n",
      "0      1   1  R-ada2a391  C-927ceb5e     C-56e39a5e   1735.06          34.70   \n",
      "1      2   2  R-ae0ef31f  C-927ceb5e     C-73ae5412   1498.24          29.96   \n",
      "2      4   4  R-8d7a7fb2  C-927ceb5e     C-451776b7   1543.01          30.86   \n",
      "3      5   5  R-b236e347  C-927ceb5e     C-d80a1e7d    310.75           6.22   \n",
      "4      6   6  R-93f348a8  C-927ceb5e     C-c92599e2   1810.21          36.20   \n",
      "\n",
      "  event_date  \n",
      "0 2024-10-16  \n",
      "1 2024-10-16  \n",
      "2 2024-10-16  \n",
      "3 2024-10-16  \n",
      "4 2024-10-16  \n",
      "index                      int64\n",
      "id                         int64\n",
      "route_id                  object\n",
      "origin_id                 object\n",
      "destination_id            object\n",
      "distance                 float64\n",
      "average_hours            float64\n",
      "event_date        datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Adding event_date column with current date\n",
    "today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "routes_df['event_date'] = pd.to_datetime(today_date)\n",
    "\n",
    "# Print the DataFrame and its data types\n",
    "print(routes_df.head())\n",
    "print(routes_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                      int64\n",
       "id                         int64\n",
       "route_id                  object\n",
       "origin_id                 object\n",
       "destination_id            object\n",
       "distance                 float64\n",
       "average_hours            float64\n",
       "event_date        datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column if it's not needed in the feature group\n",
    "if 'id' in routes_df.columns:\n",
    "    routes_df = routes_df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_fg = fs.get_or_create_feature_group(\n",
    "    name=\"routes\",\n",
    "    version=1,\n",
    "    description=\"features from routes\",\n",
    "    online_enabled=False,\n",
    "    primary_key=['index'],\n",
    "    event_time='event_date'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1810, 7)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a07f7662b6004bc8aeee5d99e28b6f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1810 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: routes_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1104021/jobs/named/routes_1_offline_fg_materialization/executions\n",
      " Done!\n"
     ]
    }
   ],
   "source": [
    "routes_fg.insert(routes_df)\n",
    "print(' Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1810, 7)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature group descriptions updated!\n"
     ]
    }
   ],
   "source": [
    "# Define feature descriptions for routes_df\n",
    "feature_descriptions_routes = [\n",
    "    {\"name\": \"route_id\", \"description\": \"unique identification for each route\"},\n",
    "    {\"name\": \"origin_id\", \"description\": \"unique identification for the origin location\"},\n",
    "    {\"name\": \"destination_id\", \"description\": \"unique identification for the destination location\"},\n",
    "    {\"name\": \"distance\", \"description\": \"distance of the route in miles\"},\n",
    "    {\"name\": \"average_hours\", \"description\": \"average time taken to travel the route in hours\"},\n",
    "    {\"name\": \"event_date\", \"description\": \"event date related to the route\"}\n",
    "]\n",
    "\n",
    "# Update feature group descriptions for routes_df\n",
    "for desc in feature_descriptions_routes:\n",
    "    routes_fg.update_feature_description(desc[\"name\"], desc[\"description\"])\n",
    "print(\" Feature group descriptions updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure statistics for the feature group\n",
    "routes_fg.statistics_config = {\n",
    "    \"enabled\": True,        # Enable statistics calculation\n",
    "    \"histograms\": True,     # Include histograms in the statistics\n",
    "    \"correlations\": True    # Include correlations in the statistics\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x16670af54c0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the statistics configuration for the feature group\n",
    "routes_fg.update_statistics_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Statistics configured and computed for routes_fg!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute statistics for the feature group\n",
    "routes_fg.update_statistics_config()\n",
    "print(\" Statistics configured and computed for routes_fg!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routes_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame\n",
    "routes_weather_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_routes_weather.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                int64\n",
       "id                   int64\n",
       "route_id            object\n",
       "date                object\n",
       "temp                 int64\n",
       "wind_speed           int64\n",
       "description         object\n",
       "precip             float64\n",
       "humidity             int64\n",
       "visibility           int64\n",
       "pressure             int64\n",
       "chanceofrain         int64\n",
       "chanceoffog          int64\n",
       "chanceofsnow         int64\n",
       "chanceofthunder      int64\n",
       "event_date          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  id    route_id                 date  temp  wind_speed description  \\\n",
      "0      1   1  R-ada2a391  2019-01-01 00:00:00    30          11  Heavy snow   \n",
      "1      2   2  R-ada2a391  2019-01-01 06:00:00    30          11  Heavy snow   \n",
      "2      3   3  R-ada2a391  2019-01-02 00:00:00    28          11      Cloudy   \n",
      "3      4   4  R-ada2a391  2019-01-02 06:00:00    27          11      Cloudy   \n",
      "4      5   5  R-ada2a391  2019-01-03 00:00:00    27           9      Cloudy   \n",
      "\n",
      "   precip  humidity  visibility  pressure  chanceofrain  chanceoffog  \\\n",
      "0     0.0        90           1      1010             0            0   \n",
      "1     0.0        91           3      1012             0            0   \n",
      "2     0.0        91           4      1013             0            0   \n",
      "3     0.0        92           6      1015             0            0   \n",
      "4     0.0        93           6      1016             0            0   \n",
      "\n",
      "   chanceofsnow  chanceofthunder event_date  \n",
      "0             0                0 2024-10-16  \n",
      "1             0                0 2024-10-16  \n",
      "2             0                0 2024-10-16  \n",
      "3             0                0 2024-10-16  \n",
      "4             0                0 2024-10-16  \n",
      "index                       int64\n",
      "id                          int64\n",
      "route_id                   object\n",
      "date                       object\n",
      "temp                        int64\n",
      "wind_speed                  int64\n",
      "description                object\n",
      "precip                    float64\n",
      "humidity                    int64\n",
      "visibility                  int64\n",
      "pressure                    int64\n",
      "chanceofrain                int64\n",
      "chanceoffog                 int64\n",
      "chanceofsnow                int64\n",
      "chanceofthunder             int64\n",
      "event_date         datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Adding event_date column with current date\n",
    "today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "routes_weather_df['event_date'] = pd.to_datetime(today_date)\n",
    "\n",
    "# Print the DataFrame and its data types\n",
    "print(routes_weather_df.head())\n",
    "print(routes_weather_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                       int64\n",
       "id                          int64\n",
       "route_id                   object\n",
       "date                       object\n",
       "temp                        int64\n",
       "wind_speed                  int64\n",
       "description                object\n",
       "precip                    float64\n",
       "humidity                    int64\n",
       "visibility                  int64\n",
       "pressure                    int64\n",
       "chanceofrain                int64\n",
       "chanceoffog                 int64\n",
       "chanceofsnow                int64\n",
       "chanceofthunder             int64\n",
       "event_date         datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_weather_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column if it's not needed in the feature group\n",
    "if 'id' in routes_weather_df.columns:\n",
    "    routes_weather_df = routes_weather_df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes_weather_fg = fs.get_or_create_feature_group(\n",
    "    name=\"routes_weather\",\n",
    "    version=1,\n",
    "    description=\"features from routes_weather\",\n",
    "    online_enabled=False,\n",
    "    primary_key=['index'],\n",
    "    event_time='event_date'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6375e1ade7a94a7798eae4385a4096d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/396149 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: routes_weather_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1104021/jobs/named/routes_weather_1_offline_fg_materialization/executions\n",
      " Done!\n"
     ]
    }
   ],
   "source": [
    "routes_weather_fg.insert(routes_weather_df)\n",
    "print(' Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature group descriptions updated!\n"
     ]
    }
   ],
   "source": [
    "# Define feature descriptions for routes_df\n",
    "feature_descriptions_routes = [\n",
    "    {\"name\": \"route_id\", \"description\": \"unique identification for each route\"},\n",
    "    {\"name\": \"origin_id\", \"description\": \"unique identification for the origin location\"},\n",
    "    {\"name\": \"destination_id\", \"description\": \"unique identification for the destination location\"},\n",
    "    {\"name\": \"distance\", \"description\": \"distance of the route in miles\"},\n",
    "    {\"name\": \"average_hours\", \"description\": \"average time taken to travel the route in hours\"},\n",
    "    {\"name\": \"event_date\", \"description\": \"event date related to the route\"}\n",
    "]\n",
    "\n",
    "# Update feature group descriptions for routes_df\n",
    "for desc in feature_descriptions_routes:\n",
    "    routes_fg.update_feature_description(desc[\"name\"], desc[\"description\"])\n",
    "print(\" Feature group descriptions updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Configure statistics for the feature group\n",
    "routes_weather_fg.statistics_config = {\n",
    "    \"enabled\": True,        # Enable statistics calculation\n",
    "    \"histograms\": True,     # Include histograms in the statistics\n",
    "    \"correlations\": True    # Include correlations in the statistics\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x267129af5f0>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Update the statistics configuration for the feature group\n",
    "routes_weather_fg.update_statistics_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Statistics configured and computed for routes_weather_fg!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute statistics for the feature group\n",
    "routes_weather_fg.update_statistics_config()\n",
    "print(\" Statistics configured and computed for routes_weather_fg!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame\n",
    "traffic_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_traffic.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index               int64\n",
       "id                  int64\n",
       "route_id           object\n",
       "date               object\n",
       "hour                int64\n",
       "no_of_vehicles    float64\n",
       "accident            int64\n",
       "event_date         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  id    route_id       date  hour  no_of_vehicles  accident event_date\n",
      "0      1   1  R-ada2a391 2019-01-01     0           669.0         0 2024-10-16\n",
      "1      2   2  R-ada2a391 2019-01-01   100           628.0         0 2024-10-16\n",
      "2      3   3  R-ada2a391 2019-01-01   200           516.0         0 2024-10-16\n",
      "3      4   4  R-ada2a391 2019-01-01   300           582.0         0 2024-10-16\n",
      "4      5   5  R-ada2a391 2019-01-01   400           564.0         0 2024-10-16\n",
      "index                      int64\n",
      "id                         int64\n",
      "route_id                  object\n",
      "date              datetime64[ns]\n",
      "hour                       int64\n",
      "no_of_vehicles           float64\n",
      "accident                   int64\n",
      "event_date        datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Adding event_date column with current date\n",
    "today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "traffic_df['event_date'] = pd.to_datetime(today_date)\n",
    "traffic_df['date'] = pd.to_datetime(traffic_df['date'])\n",
    "\n",
    "\n",
    "# Print the DataFrame and its data types\n",
    "print(traffic_df.head())\n",
    "print(traffic_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                      int64\n",
       "id                         int64\n",
       "route_id                  object\n",
       "date              datetime64[ns]\n",
       "hour                       int64\n",
       "no_of_vehicles           float64\n",
       "accident                   int64\n",
       "event_date        datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column if it's not needed in the feature group\n",
    "if 'id' in traffic_df.columns:\n",
    "    traffic_df = traffic_df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in 'no_of_vehicles' and create the missing indicator\n",
    "traffic_df['is_no_of_vehicles_missing'] = traffic_df['no_of_vehicles'].isnull().astype('int')\n",
    "\n",
    "# Ensure the correct data type\n",
    "traffic_df['is_no_of_vehicles_missing'] = traffic_df['is_no_of_vehicles_missing'].astype('int64')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic_fg = fs.get_or_create_feature_group(\n",
    "    name=\"traffic\",\n",
    "    version=1,\n",
    "    description=\"features from traffic\",\n",
    "    online_enabled=False,\n",
    "    primary_key=['index'],\n",
    "    event_time='event_date'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f126d732204460ae5aa3a76e0850c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/2458582 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: traffic_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1104021/jobs/named/traffic_1_offline_fg_materialization/executions\n",
      " Done!\n"
     ]
    }
   ],
   "source": [
    "traffic_fg.insert(traffic_df)\n",
    "print(' Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature group descriptions updated!\n"
     ]
    }
   ],
   "source": [
    "# Define feature descriptions for traffic DataFrame\n",
    "feature_descriptions_traffic = [\n",
    "    {\"name\": \"route_id\", \"description\": \"unique identification for each route\"},\n",
    "    {\"name\": \"date\", \"description\": \"date of the traffic observation\"},\n",
    "    {\"name\": \"hour\", \"description\": \"hour of the day when the observation was made\"},\n",
    "    {\"name\": \"no_of_vehicles\", \"description\": \"number of vehicles observed on the route\"},\n",
    "    {\"name\": \"accident\", \"description\": \"indicator of whether an accident occurred (0 = no, 1 = yes)\"},\n",
    "    {\"name\": \"event_date\", \"description\": \"event date related to the traffic observation\"},\n",
    "    {\"name\": \"is_no_of_vehicles_missing\", \"description\": \"indicator of whether the number of vehicles data is missing (0 = no, 1 = yes)\"}\n",
    "]\n",
    "\n",
    "# Update feature group descriptions for traffic DataFrame\n",
    "for desc in feature_descriptions_traffic:\n",
    "    traffic_fg.update_feature_description(desc[\"name\"], desc[\"description\"])\n",
    "print(\" Feature group descriptions updated!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure statistics for the traffic feature group\n",
    "traffic_fg.statistics_config = {\n",
    "    \"enabled\": True,        # Enable statistics calculation\n",
    "    \"histograms\": True,     # Include histograms in the statistics\n",
    "    \"correlations\": True    # Include correlations in the statistics\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x267128c3aa0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Update the statistics configuration for the traffic feature group\n",
    "traffic_fg.update_statistics_config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Traffic feature group statistics configured!\n"
     ]
    }
   ],
   "source": [
    "# Compute statistics for the feature group\n",
    "traffic_fg.update_statistics_config()\n",
    "print(' Traffic feature group statistics configured!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trucks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame\n",
    "trucks_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_trucks.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                     int64\n",
       "id                        int64\n",
       "truck_id                  int64\n",
       "truck_age                 int64\n",
       "load_capacity_pounds    float64\n",
       "mileage_mpg               int64\n",
       "fuel_type                object\n",
       "event_date               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trucks_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  id  truck_id  truck_age  load_capacity_pounds  mileage_mpg  \\\n",
      "0      1   1  42302347         10                3000.0           17   \n",
      "1      2   2  27867488         14               10000.0           22   \n",
      "2      3   3  13927774          8               10000.0           19   \n",
      "3      4   4  69577118          8               20000.0           19   \n",
      "4      5   5  28650047         10                4000.0           21   \n",
      "\n",
      "  fuel_type event_date  \n",
      "0       gas 2024-10-16  \n",
      "1    diesel 2024-10-16  \n",
      "2       gas 2024-10-16  \n",
      "3       gas 2024-10-16  \n",
      "4    diesel 2024-10-16  \n",
      "index                            int64\n",
      "id                               int64\n",
      "truck_id                         int64\n",
      "truck_age                        int64\n",
      "load_capacity_pounds           float64\n",
      "mileage_mpg                      int64\n",
      "fuel_type                       object\n",
      "event_date              datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Adding event_date column with current date\n",
    "today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "trucks_df['event_date'] = pd.to_datetime(today_date)\n",
    "\n",
    "\n",
    "\n",
    "# Print the DataFrame and its data types\n",
    "print(trucks_df.head())\n",
    "print(trucks_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column if it's not needed in the feature group\n",
    "if 'id' in trucks_df.columns:\n",
    "    trucks_df = trucks_df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in fuel_type with 'unknown'\n",
    "trucks_df['fuel_type'] = trucks_df['fuel_type'].fillna('unknown')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "trucks_fg = fs.get_or_create_feature_group(\n",
    "    name=\"trucks\",\n",
    "    version=1,\n",
    "    description=\"features from trucks\",\n",
    "    online_enabled=False,\n",
    "    primary_key=['index'],\n",
    "      event_time='event_date'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3203826bcebd4839a5cba0f850f2e0d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/1239 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: trucks_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1104021/jobs/named/trucks_1_offline_fg_materialization/executions\n",
      " Done!\n"
     ]
    }
   ],
   "source": [
    "trucks_fg.insert(trucks_df)\n",
    "print(' Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature group descriptions updated!\n"
     ]
    }
   ],
   "source": [
    "# Define feature descriptions for trucks DataFrame\n",
    "feature_descriptions_trucks = [\n",
    "    {\"name\": \"truck_id\", \"description\": \"unique identification number for each truck\"},\n",
    "    {\"name\": \"truck_age\", \"description\": \"age of the truck in years\"},\n",
    "    {\"name\": \"load_capacity_pounds\", \"description\": \"maximum load capacity of the truck in pounds\"},\n",
    "    {\"name\": \"mileage_mpg\", \"description\": \"fuel efficiency of the truck in miles per gallon\"},\n",
    "    {\"name\": \"fuel_type\", \"description\": \"type of fuel used by the truck (e.g., gas, diesel)\"},\n",
    "    {\"name\": \"event_date\", \"description\": \"event date related to the truck's operational data\"}\n",
    "]\n",
    "\n",
    "# Update feature group descriptions for trucks DataFrame\n",
    "for desc in feature_descriptions_trucks:\n",
    "    trucks_fg.update_feature_description(desc[\"name\"], desc[\"description\"])\n",
    "print(\" Feature group descriptions updated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure statistics for the trucks feature group\n",
    "trucks_fg.statistics_config = {\n",
    "    \"enabled\": True,        # Enable statistics calculation\n",
    "    \"histograms\": True,     # Include histograms in the statistics\n",
    "    \"correlations\": True    # Include correlations in the statistics\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x2677fcbcaa0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Update the statistics configuration for the trucks feature group\n",
    "trucks_fg.update_statistics_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trucks feature group statistics configured!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute statistics for the feature group\n",
    "trucks_fg.update_statistics_config()\n",
    "print(' Trucks feature group statistics configured!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "truck_schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame\n",
    "truck_schedule_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Cleaned_data/cleaned_truck_schedule.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    int64\n",
       "truck_id              int64\n",
       "route_id             object\n",
       "departure_date       object\n",
       "estimated_arrival    object\n",
       "delay                 int64\n",
       "event_date           object\n",
       "index                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truck_schedule_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                            int64\n",
      "truck_id                      int64\n",
      "route_id                     object\n",
      "departure_date       datetime64[ns]\n",
      "estimated_arrival    datetime64[ns]\n",
      "delay                         int64\n",
      "event_date           datetime64[ns]\n",
      "index                         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to datetime\n",
    "truck_schedule_df['departure_date'] = pd.to_datetime(truck_schedule_df['departure_date'])\n",
    "truck_schedule_df['estimated_arrival'] = pd.to_datetime(truck_schedule_df['estimated_arrival'])\n",
    "# Adding event_date column with current date\n",
    "today_date = datetime.now().strftime('%Y-%m-%d')\n",
    "truck_schedule_df['event_date'] = pd.to_datetime(today_date)\n",
    "\n",
    "\n",
    "# Check the updated data types\n",
    "print(truck_schedule_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  truck_id    route_id      departure_date             estimated_arrival  \\\n",
      "0   1  30312694  R-b236e347 2019-01-01 07:00:00 2019-01-01 13:13:12.000000000   \n",
      "1   2  59856374  R-29ea762e 2019-01-01 07:00:00 2019-01-02 04:01:12.000000000   \n",
      "2   3  12602955  R-a3d67783 2019-01-01 07:00:00 2019-01-01 07:45:36.000000000   \n",
      "3   4  46619422  R-31ec9310 2019-01-01 07:00:00 2019-01-01 20:46:48.000000000   \n",
      "4   5  10140178  R-a07c5dbd 2019-01-01 07:00:00 2019-01-01 21:34:11.999999999   \n",
      "\n",
      "   delay event_date  index  \n",
      "0      0 2024-10-16      1  \n",
      "1      0 2024-10-16      2  \n",
      "2      0 2024-10-16      3  \n",
      "3      0 2024-10-16      4  \n",
      "4      0 2024-10-16      5  \n",
      "id                            int64\n",
      "truck_id                      int64\n",
      "route_id                     object\n",
      "departure_date       datetime64[ns]\n",
      "estimated_arrival    datetime64[ns]\n",
      "delay                         int64\n",
      "event_date           datetime64[ns]\n",
      "index                         int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(truck_schedule_df.head(5))\n",
    "print(truck_schedule_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'id' column if it's not needed in the feature group\n",
    "if 'id' in truck_schedule_df.columns:\n",
    "    truck_schedule_df = truck_schedule_df.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truck_id                      int64\n",
       "route_id                     object\n",
       "departure_date       datetime64[ns]\n",
       "estimated_arrival    datetime64[ns]\n",
       "delay                         int64\n",
       "event_date           datetime64[ns]\n",
       "index                         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truck_schedule_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature group created.\n"
     ]
    }
   ],
   "source": [
    "# Create the feature group without the unnecessary columns\n",
    "truck_schedule_fg = fs.get_or_create_feature_group(\n",
    "    name=\"truck_schedule\",\n",
    "    version=1,\n",
    "    description=\"Features from truck_schedule without unnecessary columns.\",\n",
    "    online_enabled=False,\n",
    "    primary_key=['index'],\n",
    "    event_time='event_date'  \n",
    ")\n",
    "\n",
    "print(\" Feature group created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a11c6578c74247edae28a52fd06a666d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/12308 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-16 15:57:27,014 WARNING: UserWarning: Discarding nonzero nanoseconds in conversion.\n",
      "\n",
      "Launching job: truck_schedule_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1104021/jobs/named/truck_schedule_1_offline_fg_materialization/executions\n",
      " Done!\n"
     ]
    }
   ],
   "source": [
    "truck_schedule_fg.insert(truck_schedule_df)\n",
    "print(' Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature group descriptions updated!\n"
     ]
    }
   ],
   "source": [
    "# Define feature descriptions for truck_schedule DataFrame\n",
    "feature_descriptions_truck_schedule = [\n",
    "    {\"name\": \"truck_id\", \"description\": \"unique identification number for each truck\"},\n",
    "    {\"name\": \"route_id\", \"description\": \"unique identification number for each route\"},\n",
    "    {\"name\": \"departure_date\", \"description\": \"the date and time when the truck departs\"},\n",
    "    {\"name\": \"estimated_arrival\", \"description\": \"the estimated arrival date and time at the destination\"},\n",
    "    {\"name\": \"delay\", \"description\": \"the delay in minutes for the scheduled trip\"},\n",
    "    {\"name\": \"event_date\", \"description\": \"event date related to the truck's schedule\"},\n",
    "    {\"name\": \"index\", \"description\": \"index of the DataFrame entry\"}\n",
    "]\n",
    "\n",
    "# Update feature group descriptions for truck_schedule DataFrame\n",
    "for desc in feature_descriptions_truck_schedule:\n",
    "    truck_schedule_fg.update_feature_description(desc[\"name\"], desc[\"description\"])\n",
    "print(\" Feature group descriptions updated!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure statistics for the truck_schedule feature group\n",
    "truck_schedule_fg.statistics_config = {\n",
    "    \"enabled\": True,        # Enable statistics calculation\n",
    "    \"histograms\": True,     # Include histograms in the statistics\n",
    "    \"correlations\": True    # Include correlations in the statistics\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x16670de4710>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the statistics configuration for the truck_schedule feature group\n",
    "truck_schedule_fg.update_statistics_config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trucks feature group statistics configured!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute statistics for the feature group\n",
    "truck_schedule_fg.update_statistics_config()\n",
    "print(' Trucks feature group statistics configured!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieve the feature group data to see if it contains any records\n",
    "#records = truck_schedule_fg.read()\n",
    "#print(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Compute statistics for the feature group\\ntruck_schedule_fg.compute_statistics()\\nprint(' Truck schedule feature group statistics configured!')\\n\\n\\n\""
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Compute statistics for the feature group\n",
    "truck_schedule_fg.compute_statistics()\n",
    "print(' Truck schedule feature group statistics configured!')\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final_Merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1104021\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# Initialize connection to Hopsworks using API key\n",
    "project = hopsworks.login(\n",
    "    api_key_value=\"8ViXMBkcrCAUFm4Y.PEDm3J6NPoMDtf2L7MpnYsCdElsDMCPRr1RI3vbPtLnjogWE1f6hdKOoxpQbxrM0\"\n",
    ")\n",
    "\n",
    "# Get the feature store for the project\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Create a new feature store (if needed)\n",
    "# You can specify the name and other parameters if required\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hopsworks\n",
    "# import pandas as pd\n",
    "# project = hopsworks.login()\n",
    "\n",
    "# fs = project.get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the DataFrame\n",
    "final_merged_df=pd.read_csv('C:/Users/anucv/OneDrive/Desktop/AI and ML training/Machine_Learning/TRUCK_DELAY_CLASSIFICATION_PROJECT/Data/Final_Merged_data/final_merge_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truck_id                            int64\n",
       "route_id                           object\n",
       "departure_date                     object\n",
       "estimated_arrival                  object\n",
       "delay                               int64\n",
       "route_avg_temp                    float64\n",
       "route_avg_wind_speed              float64\n",
       "route_avg_precip                  float64\n",
       "route_avg_humidity                float64\n",
       "route_avg_visibility              float64\n",
       "route_avg_pressure                float64\n",
       "route_description                  object\n",
       "estimated_arrival_nearest_hour     object\n",
       "departure_date_nearest_hour        object\n",
       "origin_id                          object\n",
       "destination_id                     object\n",
       "distance                          float64\n",
       "average_hours                     float64\n",
       "origin_temp                       float64\n",
       "origin_wind_speed                 float64\n",
       "origin_description                 object\n",
       "origin_precip                     float64\n",
       "origin_humidity                   float64\n",
       "origin_visibility                 float64\n",
       "origin_pressure                   float64\n",
       "destination_temp                  float64\n",
       "destination_wind_speed            float64\n",
       "destination_description            object\n",
       "destination_precip                float64\n",
       "destination_humidity              float64\n",
       "destination_visibility            float64\n",
       "destination_pressure              float64\n",
       "avg_no_of_vehicles                float64\n",
       "accident                          float64\n",
       "truck_age                         float64\n",
       "load_capacity_pounds              float64\n",
       "mileage_mpg                       float64\n",
       "fuel_type                          object\n",
       "driver_id                          object\n",
       "name                               object\n",
       "gender                             object\n",
       "age                               float64\n",
       "experience                        float64\n",
       "driving_style                      object\n",
       "ratings                           float64\n",
       "vehicle_no                        float64\n",
       "average_speed_mph                 float64\n",
       "is_midnight                         int64\n",
       "unique_id                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 49)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "# Check the data type of the driver_id column\n",
    "print(final_merged_df['driver_id'].dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848\n"
     ]
    }
   ],
   "source": [
    "print(final_merged_df['driver_id'].isna().sum())  # Count of NaN values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_merged_df['driver_id'] = final_merged_df['driver_id'].fillna('unknown')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_merged_df['driver_id'] = final_merged_df['driver_id'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(final_merged_df['driver_id'].isna().sum())  # Should be 0 now\n",
    "# print(final_merged_df.dtypes)  # Verify that driver_id is now a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Replace NaN values in 'driver_id' with None (null)\n",
    "# final_merged_df['driver_id'] = final_merged_df['driver_id'].where(final_merged_df['driver_id'].notna(), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['truck_id', 'route_id', 'departure_date', 'estimated_arrival', 'delay',\n",
       "       'route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip',\n",
       "       'route_avg_humidity', 'route_avg_visibility', 'route_avg_pressure',\n",
       "       'route_description', 'estimated_arrival_nearest_hour',\n",
       "       'departure_date_nearest_hour', 'origin_id', 'destination_id',\n",
       "       'distance', 'average_hours', 'origin_temp', 'origin_wind_speed',\n",
       "       'origin_description', 'origin_precip', 'origin_humidity',\n",
       "       'origin_visibility', 'origin_pressure', 'destination_temp',\n",
       "       'destination_wind_speed', 'destination_description',\n",
       "       'destination_precip', 'destination_humidity', 'destination_visibility',\n",
       "       'destination_pressure', 'avg_no_of_vehicles', 'accident', 'truck_age',\n",
       "       'load_capacity_pounds', 'mileage_mpg', 'fuel_type', 'driver_id', 'name',\n",
       "       'gender', 'age', 'experience', 'driving_style', 'ratings', 'vehicle_no',\n",
       "       'average_speed_mph', 'is_midnight', 'unique_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck_id                             0\n",
      "route_id                             0\n",
      "departure_date                       0\n",
      "estimated_arrival                    0\n",
      "delay                                0\n",
      "route_avg_temp                       0\n",
      "route_avg_wind_speed                 0\n",
      "route_avg_precip                     0\n",
      "route_avg_humidity                   0\n",
      "route_avg_visibility                 0\n",
      "route_avg_pressure                   0\n",
      "route_description                    0\n",
      "estimated_arrival_nearest_hour    1600\n",
      "departure_date_nearest_hour       1600\n",
      "origin_id                         1600\n",
      "destination_id                    1600\n",
      "distance                          1600\n",
      "average_hours                     1600\n",
      "origin_temp                       1600\n",
      "origin_wind_speed                 1600\n",
      "origin_description                1600\n",
      "origin_precip                     1600\n",
      "origin_humidity                   1600\n",
      "origin_visibility                 1600\n",
      "origin_pressure                   1600\n",
      "destination_temp                  1600\n",
      "destination_wind_speed            1600\n",
      "destination_description           1600\n",
      "destination_precip                1600\n",
      "destination_humidity              1600\n",
      "destination_visibility            1600\n",
      "destination_pressure              1600\n",
      "avg_no_of_vehicles                1607\n",
      "accident                          1600\n",
      "truck_age                          659\n",
      "load_capacity_pounds               659\n",
      "mileage_mpg                        659\n",
      "fuel_type                          659\n",
      "driver_id                          848\n",
      "name                               848\n",
      "gender                             848\n",
      "age                                848\n",
      "experience                         848\n",
      "driving_style                      848\n",
      "ratings                            848\n",
      "vehicle_no                         848\n",
      "average_speed_mph                  848\n",
      "is_midnight                          0\n",
      "unique_id                            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values in the DataFrame\n",
    "print(final_merged_df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a backup of the original DataFrame\n",
    "backup_df = final_merged_df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Impute missing values for numerical columns with median\n",
    "# numerical_cols = ['route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip', \n",
    "#                   'route_avg_humidity', 'route_avg_visibility', 'route_avg_pressure', \n",
    "#                   'estimated_arrival_nearest_hour', 'departure_date_nearest_hour', \n",
    "#                   'origin_temp', 'origin_wind_speed', 'destination_temp', \n",
    "#                   'destination_wind_speed', 'average_speed_mph']\n",
    "\n",
    "# final_merged_df[numerical_cols] = final_merged_df[numerical_cols].fillna(final_merged_df[numerical_cols].median())\n",
    "\n",
    "# # Impute missing values for categorical columns with mode\n",
    "# categorical_cols = ['driver_id', 'name', 'gender', 'experience', 'driving_style', 'ratings', 'vehicle_no']\n",
    "\n",
    "# for col in categorical_cols:\n",
    "#     final_merged_df[col].fillna(final_merged_df[col].mode()[0], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 49)"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848\n",
      "848\n"
     ]
    }
   ],
   "source": [
    "print(final_merged_df['name'].isna().sum())  # Count of NaN values\n",
    "#final_merged_df['name'] = final_merged_df['name'].fillna('unknown')\n",
    "print(final_merged_df['name'].isna().sum())  # Should be 0 now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the count of NaN values\n",
    "# print(final_merged_df['gender'].isna().sum())\n",
    "\n",
    "# # Replace NaN values with the most frequent value\n",
    "# most_frequent_gender = final_merged_df['gender'].mode()[0]\n",
    "# final_merged_df['gender'] = final_merged_df['gender'].fillna(most_frequent_gender)\n",
    "\n",
    "# # Verify there are no NaN values left in the gender column\n",
    "# print(final_merged_df['gender'].isna().sum())  # Should be 0 now\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_frequent_driving_style = final_merged_df['driving_style'].mode()[0]\n",
    "# final_merged_df['driving_style'] = final_merged_df['driving_style'].fillna(most_frequent_driving_style)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['truck_id', 'route_id', 'departure_date', 'estimated_arrival', 'delay',\n",
       "       'route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip',\n",
       "       'route_avg_humidity', 'route_avg_visibility', 'route_avg_pressure',\n",
       "       'route_description', 'estimated_arrival_nearest_hour',\n",
       "       'departure_date_nearest_hour', 'origin_id', 'destination_id',\n",
       "       'distance', 'average_hours', 'origin_temp', 'origin_wind_speed',\n",
       "       'origin_description', 'origin_precip', 'origin_humidity',\n",
       "       'origin_visibility', 'origin_pressure', 'destination_temp',\n",
       "       'destination_wind_speed', 'destination_description',\n",
       "       'destination_precip', 'destination_humidity', 'destination_visibility',\n",
       "       'destination_pressure', 'avg_no_of_vehicles', 'accident', 'truck_age',\n",
       "       'load_capacity_pounds', 'mileage_mpg', 'fuel_type', 'driver_id', 'name',\n",
       "       'gender', 'age', 'experience', 'driving_style', 'ratings', 'vehicle_no',\n",
       "       'average_speed_mph', 'is_midnight', 'unique_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Origin IDs: ['C-6ea51d66' 'C-927ceb5e' 'C-c4565ee8' nan 'C-5d86b887' 'C-fc66f0ab'\n",
      " 'C-84f378bb' 'C-b5ff31cd' 'C-a9f2c329' 'C-2c9e75ef' 'C-731988ba'\n",
      " 'C-b6e04c88' 'C-6df8beaf' 'C-ff8c0c3c' 'C-451776b7' 'C-e6dcda92'\n",
      " 'C-594514f8' 'C-d9e9d934' 'C-90e30162' 'C-825b2625' 'C-3dbd8b2e'\n",
      " 'C-40a81eb1' 'C-7212cebe' 'C-c7cacd1d' 'C-b25a09de' 'C-03bb3e48'\n",
      " 'C-e5bfb4e5' 'C-328bd8d3' 'C-841ebdcb' 'C-56b68559' 'C-639c5e36'\n",
      " 'C-2bd47dc5' 'C-280b55fb' 'C-19236709' 'C-9bbf5d8a' 'C-ef47bdcd'\n",
      " 'C-01660979' 'C-419cd14c' 'C-56e39a5e' 'C-c92599e2' 'C-b5282c3b'\n",
      " 'C-d80a1e7d' 'C-2aaf0e1a' 'C-4fe0fa24' 'C-73ae5412' 'C-f5ed4c15'\n",
      " 'C-d3bb431c' 'C-f8f01604']\n",
      "Unique Destination IDs: ['C-fc66f0ab' 'C-6ea51d66' 'C-419cd14c' nan 'C-d9e9d934' 'C-731988ba'\n",
      " 'C-c4565ee8' 'C-ef47bdcd' 'C-280b55fb' 'C-2bd47dc5' 'C-5d86b887'\n",
      " 'C-b5ff31cd' 'C-01660979' 'C-e5bfb4e5' 'C-73ae5412' 'C-639c5e36'\n",
      " 'C-b6e04c88' 'C-d80a1e7d' 'C-a9f2c329' 'C-2aaf0e1a' 'C-56e39a5e'\n",
      " 'C-c92599e2' 'C-b25a09de' 'C-7212cebe' 'C-328bd8d3' 'C-03bb3e48'\n",
      " 'C-56b68559' 'C-c7cacd1d' 'C-594514f8' 'C-b5282c3b' 'C-90e30162'\n",
      " 'C-84f378bb' 'C-3dbd8b2e' 'C-40a81eb1' 'C-927ceb5e' 'C-e6dcda92'\n",
      " 'C-19236709' 'C-451776b7' 'C-9bbf5d8a' 'C-6df8beaf' 'C-2c9e75ef'\n",
      " 'C-ff8c0c3c' 'C-841ebdcb' 'C-825b2625' 'C-f5ed4c15' 'C-d3bb431c'\n",
      " 'C-4fe0fa24' 'C-f8f01604']\n",
      "truck_id                            int64\n",
      "route_id                           object\n",
      "departure_date                     object\n",
      "estimated_arrival                  object\n",
      "delay                               int64\n",
      "route_avg_temp                    float64\n",
      "route_avg_wind_speed              float64\n",
      "route_avg_precip                  float64\n",
      "route_avg_humidity                float64\n",
      "route_avg_visibility              float64\n",
      "route_avg_pressure                float64\n",
      "route_description                  object\n",
      "estimated_arrival_nearest_hour     object\n",
      "departure_date_nearest_hour        object\n",
      "origin_id                          object\n",
      "destination_id                     object\n",
      "distance                          float64\n",
      "average_hours                     float64\n",
      "origin_temp                       float64\n",
      "origin_wind_speed                 float64\n",
      "origin_description                 object\n",
      "origin_precip                     float64\n",
      "origin_humidity                   float64\n",
      "origin_visibility                 float64\n",
      "origin_pressure                   float64\n",
      "destination_temp                  float64\n",
      "destination_wind_speed            float64\n",
      "destination_description            object\n",
      "destination_precip                float64\n",
      "destination_humidity              float64\n",
      "destination_visibility            float64\n",
      "destination_pressure              float64\n",
      "avg_no_of_vehicles                float64\n",
      "accident                          float64\n",
      "truck_age                         float64\n",
      "load_capacity_pounds              float64\n",
      "mileage_mpg                       float64\n",
      "fuel_type                          object\n",
      "driver_id                          object\n",
      "name                               object\n",
      "gender                             object\n",
      "age                               float64\n",
      "experience                        float64\n",
      "driving_style                      object\n",
      "ratings                           float64\n",
      "vehicle_no                        float64\n",
      "average_speed_mph                 float64\n",
      "is_midnight                         int64\n",
      "unique_id                           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Check unique values in origin_id and destination_id\n",
    "unique_origin_ids = final_merged_df['origin_id'].unique()\n",
    "unique_destination_ids = final_merged_df['destination_id'].unique()\n",
    "\n",
    "print(\"Unique Origin IDs:\", unique_origin_ids)\n",
    "print(\"Unique Destination IDs:\", unique_destination_ids)\n",
    "\n",
    "# If you want to keep the IDs as strings:\n",
    "final_merged_df['origin_id'] = final_merged_df['origin_id'].astype(str)\n",
    "final_merged_df['destination_id'] = final_merged_df['destination_id'].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "# Check data types again to confirm changes\n",
    "print(final_merged_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck_id                            int64\n",
      "route_id                           object\n",
      "departure_date                     object\n",
      "estimated_arrival                  object\n",
      "delay                               int64\n",
      "route_avg_temp                    float64\n",
      "route_avg_wind_speed              float64\n",
      "route_avg_precip                  float64\n",
      "route_avg_humidity                float64\n",
      "route_avg_visibility              float64\n",
      "route_avg_pressure                float64\n",
      "route_description                  object\n",
      "estimated_arrival_nearest_hour     object\n",
      "departure_date_nearest_hour        object\n",
      "origin_id                          object\n",
      "destination_id                     object\n",
      "distance                          float64\n",
      "average_hours                     float64\n",
      "origin_temp                       float64\n",
      "origin_wind_speed                 float64\n",
      "origin_description                 object\n",
      "origin_precip                     float64\n",
      "origin_humidity                   float64\n",
      "origin_visibility                 float64\n",
      "origin_pressure                   float64\n",
      "destination_temp                  float64\n",
      "destination_wind_speed            float64\n",
      "destination_description            object\n",
      "destination_precip                float64\n",
      "destination_humidity              float64\n",
      "destination_visibility            float64\n",
      "destination_pressure              float64\n",
      "avg_no_of_vehicles                float64\n",
      "accident                          float64\n",
      "truck_age                         float64\n",
      "load_capacity_pounds              float64\n",
      "mileage_mpg                       float64\n",
      "fuel_type                          object\n",
      "driver_id                          object\n",
      "name                               object\n",
      "gender                             object\n",
      "age                               float64\n",
      "experience                        float64\n",
      "driving_style                      object\n",
      "ratings                           float64\n",
      "vehicle_no                        float64\n",
      "average_speed_mph                 float64\n",
      "is_midnight                         int64\n",
      "unique_id                           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Instead of converting to float, ensure IDs are treated as strings\n",
    "final_merged_df['origin_id'] = final_merged_df['origin_id'].astype(str)\n",
    "final_merged_df['destination_id'] = final_merged_df['destination_id'].astype(str)\n",
    "\n",
    "# Check for NaN values and handle them if necessary (e.g., replacing with a default value)\n",
    "final_merged_df['origin_id'].fillna('unknown', inplace=True)\n",
    "final_merged_df['destination_id'].fillna('unknown', inplace=True)\n",
    "\n",
    "# Now you can check the data types again to confirm changes\n",
    "print(final_merged_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck_id                            int64\n",
      "route_id                           object\n",
      "departure_date                     object\n",
      "estimated_arrival                  object\n",
      "delay                               int64\n",
      "route_avg_temp                    float64\n",
      "route_avg_wind_speed              float64\n",
      "route_avg_precip                  float64\n",
      "route_avg_humidity                float64\n",
      "route_avg_visibility              float64\n",
      "route_avg_pressure                float64\n",
      "route_description                  object\n",
      "estimated_arrival_nearest_hour     object\n",
      "departure_date_nearest_hour        object\n",
      "origin_id                          object\n",
      "destination_id                     object\n",
      "distance                          float64\n",
      "average_hours                     float64\n",
      "origin_temp                       float64\n",
      "origin_wind_speed                 float64\n",
      "origin_description                 object\n",
      "origin_precip                     float64\n",
      "origin_humidity                   float64\n",
      "origin_visibility                 float64\n",
      "origin_pressure                   float64\n",
      "destination_temp                  float64\n",
      "destination_wind_speed            float64\n",
      "destination_description            object\n",
      "destination_precip                float64\n",
      "destination_humidity              float64\n",
      "destination_visibility            float64\n",
      "destination_pressure              float64\n",
      "avg_no_of_vehicles                float64\n",
      "accident                          float64\n",
      "truck_age                         float64\n",
      "load_capacity_pounds              float64\n",
      "mileage_mpg                       float64\n",
      "fuel_type                          object\n",
      "driver_id                          object\n",
      "name                               object\n",
      "gender                             object\n",
      "age                               float64\n",
      "experience                        float64\n",
      "driving_style                      object\n",
      "ratings                           float64\n",
      "vehicle_no                        float64\n",
      "average_speed_mph                 float64\n",
      "is_midnight                         int64\n",
      "unique_id                           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_merged_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0 or another appropriate value\n",
    "final_merged_df['truck_age'] = final_merged_df['truck_age'].fillna(0)\n",
    "final_merged_df['mileage_mpg'] = final_merged_df['mileage_mpg'].fillna(0)\n",
    "\n",
    "# Now you can safely convert to integers\n",
    "final_merged_df['truck_age'] = final_merged_df['truck_age'].astype(int)\n",
    "final_merged_df['mileage_mpg'] = final_merged_df['mileage_mpg'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert origin_description and destination_description to categorical\n",
    "final_merged_df['origin_description'] = final_merged_df['origin_description'].astype('category')\n",
    "final_merged_df['destination_description'] = final_merged_df['destination_description'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_description         category\n",
      "destination_description    category\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_merged_df[['origin_description', 'destination_description']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_description         12265\n",
      "destination_description    12265\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Try to convert to float\n",
    "final_merged_df['origin_description'] = pd.to_numeric(final_merged_df['origin_description'], errors='coerce')\n",
    "final_merged_df['destination_description'] = pd.to_numeric(final_merged_df['destination_description'], errors='coerce')\n",
    "\n",
    "# Check for any NaNs that may have been introduced due to conversion issues\n",
    "print(final_merged_df[['origin_description', 'destination_description']].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "848\n"
     ]
    }
   ],
   "source": [
    "# Check for NaNs in 'driver_id'\n",
    "print(final_merged_df['driver_id'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df['driver_id'].fillna('default_driver_id', inplace=True)  # Replace with your default value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 49)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_id         object\n",
      "destination_id    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_merged_df[['origin_id', 'destination_id']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C-6ea51d66' 'C-927ceb5e' 'C-c4565ee8' 'nan' 'C-5d86b887' 'C-fc66f0ab'\n",
      " 'C-84f378bb' 'C-b5ff31cd' 'C-a9f2c329' 'C-2c9e75ef' 'C-731988ba'\n",
      " 'C-b6e04c88' 'C-6df8beaf' 'C-ff8c0c3c' 'C-451776b7' 'C-e6dcda92'\n",
      " 'C-594514f8' 'C-d9e9d934' 'C-90e30162' 'C-825b2625' 'C-3dbd8b2e'\n",
      " 'C-40a81eb1' 'C-7212cebe' 'C-c7cacd1d' 'C-b25a09de' 'C-03bb3e48'\n",
      " 'C-e5bfb4e5' 'C-328bd8d3' 'C-841ebdcb' 'C-56b68559' 'C-639c5e36'\n",
      " 'C-2bd47dc5' 'C-280b55fb' 'C-19236709' 'C-9bbf5d8a' 'C-ef47bdcd'\n",
      " 'C-01660979' 'C-419cd14c' 'C-56e39a5e' 'C-c92599e2' 'C-b5282c3b'\n",
      " 'C-d80a1e7d' 'C-2aaf0e1a' 'C-4fe0fa24' 'C-73ae5412' 'C-f5ed4c15'\n",
      " 'C-d3bb431c' 'C-f8f01604']\n",
      "['C-fc66f0ab' 'C-6ea51d66' 'C-419cd14c' 'nan' 'C-d9e9d934' 'C-731988ba'\n",
      " 'C-c4565ee8' 'C-ef47bdcd' 'C-280b55fb' 'C-2bd47dc5' 'C-5d86b887'\n",
      " 'C-b5ff31cd' 'C-01660979' 'C-e5bfb4e5' 'C-73ae5412' 'C-639c5e36'\n",
      " 'C-b6e04c88' 'C-d80a1e7d' 'C-a9f2c329' 'C-2aaf0e1a' 'C-56e39a5e'\n",
      " 'C-c92599e2' 'C-b25a09de' 'C-7212cebe' 'C-328bd8d3' 'C-03bb3e48'\n",
      " 'C-56b68559' 'C-c7cacd1d' 'C-594514f8' 'C-b5282c3b' 'C-90e30162'\n",
      " 'C-84f378bb' 'C-3dbd8b2e' 'C-40a81eb1' 'C-927ceb5e' 'C-e6dcda92'\n",
      " 'C-19236709' 'C-451776b7' 'C-9bbf5d8a' 'C-6df8beaf' 'C-2c9e75ef'\n",
      " 'C-ff8c0c3c' 'C-841ebdcb' 'C-825b2625' 'C-f5ed4c15' 'C-d3bb431c'\n",
      " 'C-4fe0fa24' 'C-f8f01604']\n"
     ]
    }
   ],
   "source": [
    "print(final_merged_df['origin_id'].unique())\n",
    "print(final_merged_df['destination_id'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Replace the string 'nan' with np.nan\n",
    "final_merged_df['origin_id'].replace('nan', np.nan, inplace=True)\n",
    "final_merged_df['destination_id'].replace('nan', np.nan, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to numeric, coercing errors to NaN\n",
    "final_merged_df['origin_id'] = pd.to_numeric(final_merged_df['origin_id'], errors='coerce')\n",
    "final_merged_df['destination_id'] = pd.to_numeric(final_merged_df['destination_id'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_id         12265\n",
      "destination_id    12265\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "print(final_merged_df[['origin_id', 'destination_id']].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs with a default value (e.g., 0.0)\n",
    "final_merged_df['origin_id'].fillna(0.0, inplace=True)\n",
    "final_merged_df['destination_id'].fillna(0.0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck_id                            int64\n",
      "route_id                           object\n",
      "departure_date                     object\n",
      "estimated_arrival                  object\n",
      "delay                               int64\n",
      "route_avg_temp                    float64\n",
      "route_avg_wind_speed              float64\n",
      "route_avg_precip                  float64\n",
      "route_avg_humidity                float64\n",
      "route_avg_visibility              float64\n",
      "route_avg_pressure                float64\n",
      "route_description                  object\n",
      "estimated_arrival_nearest_hour     object\n",
      "departure_date_nearest_hour        object\n",
      "origin_id                         float64\n",
      "destination_id                    float64\n",
      "distance                          float64\n",
      "average_hours                     float64\n",
      "origin_temp                       float64\n",
      "origin_wind_speed                 float64\n",
      "origin_description                float64\n",
      "origin_precip                     float64\n",
      "origin_humidity                   float64\n",
      "origin_visibility                 float64\n",
      "origin_pressure                   float64\n",
      "destination_temp                  float64\n",
      "destination_wind_speed            float64\n",
      "destination_description           float64\n",
      "destination_precip                float64\n",
      "destination_humidity              float64\n",
      "destination_visibility            float64\n",
      "destination_pressure              float64\n",
      "avg_no_of_vehicles                float64\n",
      "accident                          float64\n",
      "truck_age                           Int64\n",
      "load_capacity_pounds              float64\n",
      "mileage_mpg                         Int64\n",
      "fuel_type                          object\n",
      "driver_id                          object\n",
      "name                               object\n",
      "gender                             object\n",
      "age                               float64\n",
      "experience                        float64\n",
      "driving_style                      object\n",
      "ratings                           float64\n",
      "vehicle_no                        float64\n",
      "average_speed_mph                 float64\n",
      "is_midnight                         int64\n",
      "unique_id                           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Convert truck_age and mileage_mpg to Int64 if they're already integers\n",
    "final_merged_df['truck_age'] = final_merged_df['truck_age'].astype('Int64')  \n",
    "final_merged_df['mileage_mpg'] = final_merged_df['mileage_mpg'].astype('Int64')\n",
    "\n",
    "# Check the types\n",
    "print(final_merged_df.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NaN values with None\n",
    "final_merged_df = final_merged_df.where(pd.notnull(final_merged_df), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck_id                            int64\n",
      "route_id                           object\n",
      "departure_date                     object\n",
      "estimated_arrival                  object\n",
      "delay                               int64\n",
      "route_avg_temp                    float64\n",
      "route_avg_wind_speed              float64\n",
      "route_avg_precip                  float64\n",
      "route_avg_humidity                float64\n",
      "route_avg_visibility              float64\n",
      "route_avg_pressure                float64\n",
      "route_description                  object\n",
      "estimated_arrival_nearest_hour     object\n",
      "departure_date_nearest_hour        object\n",
      "origin_id                         float64\n",
      "destination_id                    float64\n",
      "distance                          float64\n",
      "average_hours                     float64\n",
      "origin_temp                       float64\n",
      "origin_wind_speed                 float64\n",
      "origin_description                float64\n",
      "origin_precip                     float64\n",
      "origin_humidity                   float64\n",
      "origin_visibility                 float64\n",
      "origin_pressure                   float64\n",
      "destination_temp                  float64\n",
      "destination_wind_speed            float64\n",
      "destination_description           float64\n",
      "destination_precip                float64\n",
      "destination_humidity              float64\n",
      "destination_visibility            float64\n",
      "destination_pressure              float64\n",
      "avg_no_of_vehicles                float64\n",
      "accident                          float64\n",
      "truck_age                           Int64\n",
      "load_capacity_pounds              float64\n",
      "mileage_mpg                         Int64\n",
      "fuel_type                          object\n",
      "driver_id                          object\n",
      "name                               object\n",
      "gender                             object\n",
      "age                               float64\n",
      "experience                        float64\n",
      "driving_style                      object\n",
      "ratings                           float64\n",
      "vehicle_no                        float64\n",
      "average_speed_mph                 float64\n",
      "is_midnight                         int64\n",
      "unique_id                           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(final_merged_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_fg = fs.get_or_create_feature_group(\n",
    "    name=\"final_merged\",\n",
    "    version=1,\n",
    "    description=\"features from final_merged dataframe\",\n",
    "    online_enabled=False,\n",
    "    primary_key=['unique_id']  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numeric, setting errors='coerce' will convert non-convertible values to NaN\n",
    "final_merged_df['estimated_arrival_nearest_hour'] = pd.to_numeric(final_merged_df['estimated_arrival_nearest_hour'], errors='coerce')\n",
    "final_merged_df['departure_date_nearest_hour'] = pd.to_numeric(final_merged_df['departure_date_nearest_hour'], errors='coerce')\n",
    "\n",
    "# Optional: Fill NaNs with a default value or drop them if necessary\n",
    "# final_merged_df['estimated_arrival_nearest_hour'].fillna(0, inplace=True)\n",
    "# final_merged_df['departure_date_nearest_hour'].fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165234d0200142a78c349fb19da878f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/12265 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: final_merged_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/1104021/jobs/named/final_merged_1_offline_fg_materialization/executions\n",
      " Done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Insert into the feature store\n",
    "final_merged_fg.insert(final_merged_df)\n",
    "print(' Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Feature group descriptions updated!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define feature descriptions for final_merged DataFrame\n",
    "feature_descriptions_final_merged = [\n",
    "                    {\"name\": 'unique_id', \"description\": \"the unique identifier for each record\"},\n",
    "                    {\"name\": 'truck_id', \"description\": \"the unique identifier of the truck\"},\n",
    "                    {\"name\": 'route_id', \"description\": \"the unique identifier of the route\"},\n",
    "                    {\"name\": 'departure_date', \"description\": \"departure DateTime of the truck\"},\n",
    "                    {\"name\": 'estimated_arrival', \"description\": \"estimated arrival DateTime of the truck\"},\n",
    "                    {\"name\": 'delay', \"description\": \"binary variable if the trucks arrival was delayed, 0 for on-time arrival and 1 for delayed arrival\"},\n",
    "                    {\"name\": 'route_avg_temp', \"description\":  'Average temperature in Fahrenheit'},\n",
    "                    {\"name\": 'route_avg_wind_speed', \"description\":  'Average wind speed in miles per hour'},\n",
    "                    {\"name\": 'route_avg_precip', \"description\":  'Average precipitation in inches'},\n",
    "                    {\"name\": 'route_avg_humidity', \"description\":  'Average humidity observed'},\n",
    "                    {\"name\": 'route_avg_visibility', \"description\":  'Average visibility observed in miles per hour'},\n",
    "                    {\"name\": 'route_avg_pressure', \"description\":  'Average pressure observed in millibar'},\n",
    "                    {\"name\": 'route_description', \"description\":  'description of the weather conditions such as Clear, Cloudy, etc'},\n",
    "                    {\"name\": 'estimated_arrival_nearest_hour', \"description\":  'estimated arrival DateTime of the truck'},\n",
    "                    {\"name\": 'departure_date_nearest_hour', \"description\":  'departure DateTime of the truck'},\n",
    "                    {\"name\": 'origin_id', \"description\": \"the city identification number for the origin city\"},\n",
    "                    {\"name\": 'destination_id', \"description\": \" the city identification number for the destination\"},\n",
    "                    {\"name\": 'distance', \"description\": \" the distance between the origin and destination cities in miles\"},\n",
    "                    {\"name\": 'average_hours', \"description\": \"average time needed to travel from the origin to the destination in hours\"},\n",
    "                    {\"name\": 'origin_temp', \"description\":  'temperature in Fahrenheit'},\n",
    "                    {\"name\": 'origin_wind_speed', \"description\":  'wind speed in miles per hour'},\n",
    "                    {\"name\": 'origin_description', \"description\":  'description of the weather conditions such as Clear, Cloudy, etc'},\n",
    "                    {\"name\": 'origin_precip', \"description\":  'precipitation in inches'},\n",
    "                    {\"name\": 'origin_humidity', \"description\":  'humidity observed'},\n",
    "                    {\"name\": 'origin_visibility', \"description\":  'visibility observed in miles per hour'},\n",
    "                    {\"name\": 'origin_pressure', \"description\":  'pressure observed in millibar'},\n",
    "                    {\"name\": 'destination_temp', \"description\":  'temperature in Fahrenheit'},\n",
    "                    {\"name\": 'destination_wind_speed', \"description\":  'wind speed in miles per hour'},\n",
    "                    {\"name\": 'destination_description', \"description\":  'description of the weather conditions such as Clear, Cloudy, etc'},\n",
    "                    {\"name\": 'destination_precip', \"description\":  'precipitation in inches'},\n",
    "                    {\"name\": 'destination_humidity', \"description\":  'humidity observed'},\n",
    "                    {\"name\": 'destination_visibility', \"description\":  'visibility observed in miles per hour'},\n",
    "                    {\"name\": 'destination_pressure', \"description\":  'pressure observed in millibar'},\n",
    "                    {\"name\": 'avg_no_of_vehicles', \"description\": \"the average number of vehicles observed on the route\"},\n",
    "                    {\"name\": 'accident', \"description\": \"binary variable to denote if an accident was observed\"},\n",
    "                    {\"name\":'truck_age',\"description\":\"age of the truck in years\"},\n",
    "                    {\"name\":'load_capacity_pounds',\"description\":\"loading capacity of the truck in years\"},\n",
    "                    {\"name\":'mileage_mpg',\"description\": \"mileage of the truck in miles per gallon\"},\n",
    "                    {\"name\":'fuel_type',\"description\":\"fuel type of the truck\"},\n",
    "                    {\"name\": \"driver_id\", \"description\": \"unique identification for each driver\"},\n",
    "                    {\"name\": \"name\", \"description\": \" name of the truck driver\"},\n",
    "                    {\"name\": \"gender\", \"description\": \"gender of the truck driver\"},\n",
    "                    {\"name\": \"age\", \"description\": \"age of the truck driver\"},\n",
    "                    {\"name\": \"experience\", \"description\": \" experience of the truck driver in years\"},\n",
    "                    {\"name\": \"driving_style\", \"description\": \"driving style of the truck driver, conservative or proactive\"},\n",
    "                    {\"name\": \"ratings\", \"description\": \"average rating of the truck driver on a scale of 1 to 5\"},\n",
    "                    {\"name\": \"vehicle_no\", \"description\": \"the number of the drivers truck\"},\n",
    "                    {\"name\": \"average_speed_mph\", \"description\": \"average speed the truck driver in miles per hour\"},\n",
    "                    {\"name\": 'is_midnight', \"description\": \"binary variable to denote if it was midnight\"}\n",
    "                \n",
    "                ]\n",
    "\n",
    "# Update feature group descriptions for truck_schedule DataFrame\n",
    "for desc in feature_descriptions_final_merged:\n",
    "    final_merged_fg.update_feature_description(desc[\"name\"], desc[\"description\"])\n",
    "print(\" Feature group descriptions updated!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure statistics for the final merged feature group\n",
    "final_merged_fg.statistics_config = {\n",
    "    \"enabled\": True,        # Enable statistics calculation\n",
    "    \"histograms\": True,     # Include histograms in the statistics\n",
    "    \"correlations\": True    # Include correlations in the statistics\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x166020b6b10>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the statistics configuration for the truck_schedule feature group\n",
    "final_merged_fg.update_statistics_config()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 49)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51834, 18)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1209, 11)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1810, 7)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396149, 15)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "routes_weather_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2458582, 8)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1239, 7)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trucks_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12308, 7)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truck_schedule_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 49)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
