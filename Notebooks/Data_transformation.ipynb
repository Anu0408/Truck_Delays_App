{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1104021\n",
      "2024-10-19 19:22:46,067 WARNING: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
      "\n",
      "2024-10-19 19:22:46,067 WARNING: using legacy validation callback\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (1.81s) \n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "\n",
    "# Initialize connection to Hopsworks using API key\n",
    "project = hopsworks.login(api_key_value=\"8ViXMBkcrCAUFm4Y.PEDm3J6NPoMDtf2L7MpnYsCdElsDMCPRr1RI3vbPtLnjogWE1f6hdKOoxpQbxrM0\")\n",
    "# Access the feature store for the project\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# Retrieve the feature group\n",
    "final_merged_fg = fs.get_feature_group(name=\"final_merged\", version=1)\n",
    "\n",
    "# Read the feature group as a DataFrame\n",
    "final_merged_df = final_merged_fg.read()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truck_id</th>\n",
       "      <th>route_id</th>\n",
       "      <th>departure_date</th>\n",
       "      <th>estimated_arrival</th>\n",
       "      <th>delay</th>\n",
       "      <th>route_avg_temp</th>\n",
       "      <th>route_avg_wind_speed</th>\n",
       "      <th>route_avg_precip</th>\n",
       "      <th>route_avg_humidity</th>\n",
       "      <th>route_avg_visibility</th>\n",
       "      <th>...</th>\n",
       "      <th>name</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>experience</th>\n",
       "      <th>driving_style</th>\n",
       "      <th>ratings</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>average_speed_mph</th>\n",
       "      <th>is_midnight</th>\n",
       "      <th>unique_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50064164</td>\n",
       "      <td>R-20376100</td>\n",
       "      <td>2019-02-12 07:00:00</td>\n",
       "      <td>2019-02-12 22:25:12</td>\n",
       "      <td>0</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>81.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Sandra Wilson</td>\n",
       "      <td>female</td>\n",
       "      <td>44.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>conservative</td>\n",
       "      <td>6.0</td>\n",
       "      <td>50064164.0</td>\n",
       "      <td>44.74</td>\n",
       "      <td>0</td>\n",
       "      <td>8518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60858923</td>\n",
       "      <td>R-461413e3</td>\n",
       "      <td>2019-01-01 07:00:00</td>\n",
       "      <td>2019-01-07 00:55:48</td>\n",
       "      <td>0</td>\n",
       "      <td>68.785714</td>\n",
       "      <td>11.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>Jose Martin</td>\n",
       "      <td>male</td>\n",
       "      <td>52.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>proactive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60858923.0</td>\n",
       "      <td>60.74</td>\n",
       "      <td>1</td>\n",
       "      <td>7091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24859831</td>\n",
       "      <td>R-18468971</td>\n",
       "      <td>2019-01-13 07:00:00</td>\n",
       "      <td>2019-01-13 23:40:12</td>\n",
       "      <td>0</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.5</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>Luke Kennedy</td>\n",
       "      <td>male</td>\n",
       "      <td>42.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>proactive</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24859831.0</td>\n",
       "      <td>60.48</td>\n",
       "      <td>0</td>\n",
       "      <td>5129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31827682</td>\n",
       "      <td>R-6f2f34a8</td>\n",
       "      <td>2019-01-16 07:00:00</td>\n",
       "      <td>2019-01-16 13:04:48</td>\n",
       "      <td>0</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>79.0</td>\n",
       "      <td>5.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>George Webb</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>proactive</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31827682.0</td>\n",
       "      <td>59.97</td>\n",
       "      <td>0</td>\n",
       "      <td>6443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30822651</td>\n",
       "      <td>R-c5c0de8d</td>\n",
       "      <td>2019-01-25 07:00:00</td>\n",
       "      <td>2019-01-26 05:13:12</td>\n",
       "      <td>1</td>\n",
       "      <td>65.200000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>90.6</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>Kimberly Torres</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>conservative</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30822651.0</td>\n",
       "      <td>54.19</td>\n",
       "      <td>1</td>\n",
       "      <td>6231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   truck_id    route_id       departure_date    estimated_arrival  delay  \\\n",
       "0  50064164  R-20376100  2019-02-12 07:00:00  2019-02-12 22:25:12      0   \n",
       "1  60858923  R-461413e3  2019-01-01 07:00:00  2019-01-07 00:55:48      0   \n",
       "2  24859831  R-18468971  2019-01-13 07:00:00  2019-01-13 23:40:12      0   \n",
       "3  31827682  R-6f2f34a8  2019-01-16 07:00:00  2019-01-16 13:04:48      0   \n",
       "4  30822651  R-c5c0de8d  2019-01-25 07:00:00  2019-01-26 05:13:12      1   \n",
       "\n",
       "   route_avg_temp  route_avg_wind_speed  route_avg_precip  route_avg_humidity  \\\n",
       "0       74.000000              4.500000          0.000000                81.0   \n",
       "1       68.785714             11.142857          0.000000                71.0   \n",
       "2       53.000000             11.500000          0.000000                75.5   \n",
       "3       78.000000              9.000000          0.033333                79.0   \n",
       "4       65.200000              8.000000          0.040000                90.6   \n",
       "\n",
       "   route_avg_visibility  ...             name  gender   age  experience  \\\n",
       "0              6.000000  ...    Sandra Wilson  female  44.0        13.0   \n",
       "1              5.500000  ...      Jose Martin    male  52.0        21.0   \n",
       "2              6.000000  ...     Luke Kennedy    male  42.0         2.0   \n",
       "3              5.333333  ...      George Webb    male  45.0        16.0   \n",
       "4              5.200000  ...  Kimberly Torres  female  55.0        24.0   \n",
       "\n",
       "   driving_style  ratings  vehicle_no  average_speed_mph  is_midnight  \\\n",
       "0   conservative      6.0  50064164.0              44.74            0   \n",
       "1      proactive      4.0  60858923.0              60.74            1   \n",
       "2      proactive      7.0  24859831.0              60.48            0   \n",
       "3      proactive      9.0  31827682.0              59.97            0   \n",
       "4   conservative      9.0  30822651.0              54.19            1   \n",
       "\n",
       "   unique_id  \n",
       "0       8518  \n",
       "1       7091  \n",
       "2       5129  \n",
       "3       6443  \n",
       "4       6231  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 49)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12265 entries, 0 to 12264\n",
      "Data columns (total 49 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   truck_id                        12265 non-null  int64  \n",
      " 1   route_id                        12265 non-null  object \n",
      " 2   departure_date                  12265 non-null  object \n",
      " 3   estimated_arrival               12265 non-null  object \n",
      " 4   delay                           12265 non-null  int64  \n",
      " 5   route_avg_temp                  12265 non-null  float64\n",
      " 6   route_avg_wind_speed            12265 non-null  float64\n",
      " 7   route_avg_precip                12265 non-null  float64\n",
      " 8   route_avg_humidity              12265 non-null  float64\n",
      " 9   route_avg_visibility            12265 non-null  float64\n",
      " 10  route_avg_pressure              12265 non-null  float64\n",
      " 11  route_description               12265 non-null  object \n",
      " 12  estimated_arrival_nearest_hour  0 non-null      float64\n",
      " 13  departure_date_nearest_hour     0 non-null      float64\n",
      " 14  origin_id                       12265 non-null  float64\n",
      " 15  destination_id                  12265 non-null  float64\n",
      " 16  distance                        10665 non-null  float64\n",
      " 17  average_hours                   10665 non-null  float64\n",
      " 18  origin_temp                     10665 non-null  float64\n",
      " 19  origin_wind_speed               10665 non-null  float64\n",
      " 20  origin_description              0 non-null      float64\n",
      " 21  origin_precip                   10665 non-null  float64\n",
      " 22  origin_humidity                 10665 non-null  float64\n",
      " 23  origin_visibility               10665 non-null  float64\n",
      " 24  origin_pressure                 10665 non-null  float64\n",
      " 25  destination_temp                10665 non-null  float64\n",
      " 26  destination_wind_speed          10665 non-null  float64\n",
      " 27  destination_description         0 non-null      float64\n",
      " 28  destination_precip              10665 non-null  float64\n",
      " 29  destination_humidity            10665 non-null  float64\n",
      " 30  destination_visibility          10665 non-null  float64\n",
      " 31  destination_pressure            10665 non-null  float64\n",
      " 32  avg_no_of_vehicles              10658 non-null  float64\n",
      " 33  accident                        10665 non-null  float64\n",
      " 34  truck_age                       12265 non-null  int64  \n",
      " 35  load_capacity_pounds            11606 non-null  float64\n",
      " 36  mileage_mpg                     12265 non-null  int64  \n",
      " 37  fuel_type                       11606 non-null  object \n",
      " 38  driver_id                       12265 non-null  object \n",
      " 39  name                            11417 non-null  object \n",
      " 40  gender                          11417 non-null  object \n",
      " 41  age                             11417 non-null  float64\n",
      " 42  experience                      11417 non-null  float64\n",
      " 43  driving_style                   11417 non-null  object \n",
      " 44  ratings                         11417 non-null  float64\n",
      " 45  vehicle_no                      11417 non-null  float64\n",
      " 46  average_speed_mph               11417 non-null  float64\n",
      " 47  is_midnight                     12265 non-null  int64  \n",
      " 48  unique_id                       12265 non-null  int64  \n",
      "dtypes: float64(34), int64(6), object(9)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "final_merged_df.info()  # Verify the structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All expected columns are present.\n",
      "Non-null counts for datetime columns after conversion:\n",
      "departure_date                        0\n",
      "estimated_arrival                     0\n",
      "estimated_arrival_nearest_hour    12265\n",
      "departure_date_nearest_hour       12265\n",
      "dtype: int64\n",
      "Data types after adjustments:\n",
      "truck_id                                   int64\n",
      "route_id                                  object\n",
      "departure_date                    datetime64[ns]\n",
      "estimated_arrival                 datetime64[ns]\n",
      "delay                                      int64\n",
      "route_avg_temp                           float64\n",
      "route_avg_wind_speed                     float64\n",
      "route_avg_precip                         float64\n",
      "route_avg_humidity                       float64\n",
      "route_avg_visibility                     float64\n",
      "route_avg_pressure                       float64\n",
      "route_description                         object\n",
      "estimated_arrival_nearest_hour    datetime64[ns]\n",
      "departure_date_nearest_hour       datetime64[ns]\n",
      "origin_id                                 object\n",
      "destination_id                            object\n",
      "distance                                 float64\n",
      "average_hours                            float64\n",
      "origin_temp                              float64\n",
      "origin_wind_speed                        float64\n",
      "origin_description                        object\n",
      "origin_precip                            float64\n",
      "origin_humidity                          float64\n",
      "origin_visibility                        float64\n",
      "origin_pressure                          float64\n",
      "destination_temp                         float64\n",
      "destination_wind_speed                   float64\n",
      "destination_description                   object\n",
      "destination_precip                       float64\n",
      "destination_humidity                     float64\n",
      "destination_visibility                   float64\n",
      "destination_pressure                     float64\n",
      "avg_no_of_vehicles                       float64\n",
      "accident                                 float64\n",
      "truck_age                                  int64\n",
      "load_capacity_pounds                     float64\n",
      "mileage_mpg                                int64\n",
      "fuel_type                                 object\n",
      "driver_id                                 object\n",
      "name                                      object\n",
      "gender                                    object\n",
      "age                                      float64\n",
      "experience                               float64\n",
      "driving_style                             object\n",
      "ratings                                  float64\n",
      "vehicle_no                               float64\n",
      "average_speed_mph                        float64\n",
      "is_midnight                                int64\n",
      "unique_id                                  int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Step 1: Convert object types to datetime\n",
    "datetime_columns = [\n",
    "    'departure_date', \n",
    "    'estimated_arrival', \n",
    "    'estimated_arrival_nearest_hour', \n",
    "    'departure_date_nearest_hour'\n",
    "]\n",
    "\n",
    "for col in datetime_columns:\n",
    "    final_merged_df[col] = pd.to_datetime(final_merged_df[col], errors='coerce')  # Coerce errors to handle any invalid dates\n",
    "\n",
    "# Step 2: Adjust data types for identifiers and descriptions\n",
    "final_merged_df['origin_id'] = final_merged_df['origin_id'].astype('object')\n",
    "final_merged_df['destination_id'] = final_merged_df['destination_id'].astype('object')\n",
    "final_merged_df['origin_description'] = final_merged_df['origin_description'].astype('object')\n",
    "final_merged_df['destination_description'] = final_merged_df['destination_description'].astype('object')\n",
    "\n",
    "# Step 3: Validation\n",
    "# Check for expected columns\n",
    "expected_columns = [\n",
    "    'unique_id', 'truck_id', 'route_id', 'departure_date', 'estimated_arrival',\n",
    "    'delay', 'route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip',\n",
    "    'route_avg_humidity', 'route_avg_visibility', 'route_avg_pressure',\n",
    "    'route_description', 'estimated_arrival_nearest_hour', 'departure_date_nearest_hour',\n",
    "    'origin_id', 'destination_id', 'distance', 'average_hours', 'origin_temp',\n",
    "    'origin_wind_speed', 'origin_description', 'origin_precip', 'origin_humidity',\n",
    "    'origin_visibility', 'origin_pressure', 'destination_temp', 'destination_wind_speed',\n",
    "    'destination_description', 'destination_precip', 'destination_humidity',\n",
    "    'destination_visibility', 'destination_pressure', 'avg_no_of_vehicles',\n",
    "    'accident', 'truck_age', 'load_capacity_pounds', 'mileage_mpg', 'fuel_type',\n",
    "    'driver_id', 'name', 'gender', 'age', 'experience', 'driving_style', \n",
    "    'ratings', 'vehicle_no', 'average_speed_mph', 'is_midnight'\n",
    "]\n",
    "\n",
    "# Validate columns\n",
    "missing_columns = [col for col in expected_columns if col not in final_merged_df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Missing columns in DataFrame: {missing_columns}\")\n",
    "else:\n",
    "    print(\"All expected columns are present.\")\n",
    "\n",
    "# Check for non-null values in critical columns\n",
    "non_null_counts = final_merged_df[datetime_columns].isnull().sum()\n",
    "print(\"Non-null counts for datetime columns after conversion:\")\n",
    "print(non_null_counts)\n",
    "\n",
    "# Final output\n",
    "print(\"Data types after adjustments:\")\n",
    "print(final_merged_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12265 entries, 0 to 12264\n",
      "Data columns (total 49 columns):\n",
      " #   Column                          Non-Null Count  Dtype         \n",
      "---  ------                          --------------  -----         \n",
      " 0   truck_id                        12265 non-null  int64         \n",
      " 1   route_id                        12265 non-null  object        \n",
      " 2   departure_date                  12265 non-null  datetime64[ns]\n",
      " 3   estimated_arrival               12265 non-null  datetime64[ns]\n",
      " 4   delay                           12265 non-null  int64         \n",
      " 5   route_avg_temp                  12265 non-null  float64       \n",
      " 6   route_avg_wind_speed            12265 non-null  float64       \n",
      " 7   route_avg_precip                12265 non-null  float64       \n",
      " 8   route_avg_humidity              12265 non-null  float64       \n",
      " 9   route_avg_visibility            12265 non-null  float64       \n",
      " 10  route_avg_pressure              12265 non-null  float64       \n",
      " 11  route_description               12265 non-null  object        \n",
      " 12  estimated_arrival_nearest_hour  0 non-null      datetime64[ns]\n",
      " 13  departure_date_nearest_hour     0 non-null      datetime64[ns]\n",
      " 14  origin_id                       12265 non-null  object        \n",
      " 15  destination_id                  12265 non-null  object        \n",
      " 16  distance                        10665 non-null  float64       \n",
      " 17  average_hours                   10665 non-null  float64       \n",
      " 18  origin_temp                     10665 non-null  float64       \n",
      " 19  origin_wind_speed               10665 non-null  float64       \n",
      " 20  origin_description              0 non-null      object        \n",
      " 21  origin_precip                   10665 non-null  float64       \n",
      " 22  origin_humidity                 10665 non-null  float64       \n",
      " 23  origin_visibility               10665 non-null  float64       \n",
      " 24  origin_pressure                 10665 non-null  float64       \n",
      " 25  destination_temp                10665 non-null  float64       \n",
      " 26  destination_wind_speed          10665 non-null  float64       \n",
      " 27  destination_description         0 non-null      object        \n",
      " 28  destination_precip              10665 non-null  float64       \n",
      " 29  destination_humidity            10665 non-null  float64       \n",
      " 30  destination_visibility          10665 non-null  float64       \n",
      " 31  destination_pressure            10665 non-null  float64       \n",
      " 32  avg_no_of_vehicles              10658 non-null  float64       \n",
      " 33  accident                        10665 non-null  float64       \n",
      " 34  truck_age                       12265 non-null  int64         \n",
      " 35  load_capacity_pounds            11606 non-null  float64       \n",
      " 36  mileage_mpg                     12265 non-null  int64         \n",
      " 37  fuel_type                       11606 non-null  object        \n",
      " 38  driver_id                       12265 non-null  object        \n",
      " 39  name                            11417 non-null  object        \n",
      " 40  gender                          11417 non-null  object        \n",
      " 41  age                             11417 non-null  float64       \n",
      " 42  experience                      11417 non-null  float64       \n",
      " 43  driving_style                   11417 non-null  object        \n",
      " 44  ratings                         11417 non-null  float64       \n",
      " 45  vehicle_no                      11417 non-null  float64       \n",
      " 46  average_speed_mph               11417 non-null  float64       \n",
      " 47  is_midnight                     12265 non-null  int64         \n",
      " 48  unique_id                       12265 non-null  int64         \n",
      "dtypes: datetime64[ns](4), float64(28), int64(6), object(11)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "final_merged_df.info()  # Verify the structure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Data Type  Null Values\n",
      "truck_id                                 int64            0\n",
      "route_id                                object            0\n",
      "departure_date                  datetime64[ns]            0\n",
      "estimated_arrival               datetime64[ns]            0\n",
      "delay                                    int64            0\n",
      "route_avg_temp                         float64            0\n",
      "route_avg_wind_speed                   float64            0\n",
      "route_avg_precip                       float64            0\n",
      "route_avg_humidity                     float64            0\n",
      "route_avg_visibility                   float64            0\n",
      "route_avg_pressure                     float64            0\n",
      "route_description                       object            0\n",
      "estimated_arrival_nearest_hour  datetime64[ns]        12265\n",
      "departure_date_nearest_hour     datetime64[ns]        12265\n",
      "origin_id                               object            0\n",
      "destination_id                          object            0\n",
      "distance                               float64         1600\n",
      "average_hours                          float64         1600\n",
      "origin_temp                            float64         1600\n",
      "origin_wind_speed                      float64         1600\n",
      "origin_description                      object        12265\n",
      "origin_precip                          float64         1600\n",
      "origin_humidity                        float64         1600\n",
      "origin_visibility                      float64         1600\n",
      "origin_pressure                        float64         1600\n",
      "destination_temp                       float64         1600\n",
      "destination_wind_speed                 float64         1600\n",
      "destination_description                 object        12265\n",
      "destination_precip                     float64         1600\n",
      "destination_humidity                   float64         1600\n",
      "destination_visibility                 float64         1600\n",
      "destination_pressure                   float64         1600\n",
      "avg_no_of_vehicles                     float64         1607\n",
      "accident                               float64         1600\n",
      "truck_age                                int64            0\n",
      "load_capacity_pounds                   float64          659\n",
      "mileage_mpg                              int64            0\n",
      "fuel_type                               object          659\n",
      "driver_id                               object            0\n",
      "name                                    object          848\n",
      "gender                                  object          848\n",
      "age                                    float64          848\n",
      "experience                             float64          848\n",
      "driving_style                           object          848\n",
      "ratings                                float64          848\n",
      "vehicle_no                             float64          848\n",
      "average_speed_mph                      float64          848\n",
      "is_midnight                              int64            0\n",
      "unique_id                                int64            0\n",
      "Memory Usage:\n",
      "Index                                132\n",
      "truck_id                           98120\n",
      "route_id                          723635\n",
      "departure_date                     98120\n",
      "estimated_arrival                  98120\n",
      "delay                              98120\n",
      "route_avg_temp                     98120\n",
      "route_avg_wind_speed               98120\n",
      "route_avg_precip                   98120\n",
      "route_avg_humidity                 98120\n",
      "route_avg_visibility               98120\n",
      "route_avg_pressure                 98120\n",
      "route_description                 715773\n",
      "estimated_arrival_nearest_hour     98120\n",
      "departure_date_nearest_hour        98120\n",
      "origin_id                         392480\n",
      "destination_id                    392480\n",
      "distance                           98120\n",
      "average_hours                      98120\n",
      "origin_temp                        98120\n",
      "origin_wind_speed                  98120\n",
      "origin_description                392480\n",
      "origin_precip                      98120\n",
      "origin_humidity                    98120\n",
      "origin_visibility                  98120\n",
      "origin_pressure                    98120\n",
      "destination_temp                   98120\n",
      "destination_wind_speed             98120\n",
      "destination_description           392480\n",
      "destination_precip                 98120\n",
      "destination_humidity               98120\n",
      "destination_visibility             98120\n",
      "destination_pressure               98120\n",
      "avg_no_of_vehicles                 98120\n",
      "accident                           98120\n",
      "truck_age                          98120\n",
      "load_capacity_pounds               98120\n",
      "mileage_mpg                        98120\n",
      "fuel_type                         639279\n",
      "driver_id                         729571\n",
      "name                              731478\n",
      "gender                            626819\n",
      "age                                98120\n",
      "experience                         98120\n",
      "driving_style                     699149\n",
      "ratings                            98120\n",
      "vehicle_no                         98120\n",
      "average_speed_mph                  98120\n",
      "is_midnight                        98120\n",
      "unique_id                          98120\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check data types and null values\n",
    "data_types = final_merged_df.dtypes\n",
    "null_counts = final_merged_df.isnull().sum()\n",
    "\n",
    "# Summary of data types and null values\n",
    "summary = pd.DataFrame({'Data Type': data_types, 'Null Values': null_counts})\n",
    "print(summary)\n",
    "\n",
    "# Check memory usage\n",
    "memory_usage = final_merged_df.memory_usage(deep=True)\n",
    "print(f\"Memory Usage:\\n{memory_usage}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truck_id                              0\n",
       "route_id                              0\n",
       "departure_date                        0\n",
       "estimated_arrival                     0\n",
       "delay                                 0\n",
       "route_avg_temp                        0\n",
       "route_avg_wind_speed                  0\n",
       "route_avg_precip                      0\n",
       "route_avg_humidity                    0\n",
       "route_avg_visibility                  0\n",
       "route_avg_pressure                    0\n",
       "route_description                     0\n",
       "estimated_arrival_nearest_hour    12265\n",
       "departure_date_nearest_hour       12265\n",
       "origin_id                             0\n",
       "destination_id                        0\n",
       "distance                           1600\n",
       "average_hours                      1600\n",
       "origin_temp                        1600\n",
       "origin_wind_speed                  1600\n",
       "origin_description                12265\n",
       "origin_precip                      1600\n",
       "origin_humidity                    1600\n",
       "origin_visibility                  1600\n",
       "origin_pressure                    1600\n",
       "destination_temp                   1600\n",
       "destination_wind_speed             1600\n",
       "destination_description           12265\n",
       "destination_precip                 1600\n",
       "destination_humidity               1600\n",
       "destination_visibility             1600\n",
       "destination_pressure               1600\n",
       "avg_no_of_vehicles                 1607\n",
       "accident                           1600\n",
       "truck_age                             0\n",
       "load_capacity_pounds                659\n",
       "mileage_mpg                           0\n",
       "fuel_type                           659\n",
       "driver_id                             0\n",
       "name                                848\n",
       "gender                              848\n",
       "age                                 848\n",
       "experience                          848\n",
       "driving_style                       848\n",
       "ratings                             848\n",
       "vehicle_no                          848\n",
       "average_speed_mph                   848\n",
       "is_midnight                           0\n",
       "unique_id                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.isnull().sum()  # Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated_arrival_nearest_hour    12265\n",
      "departure_date_nearest_hour       12265\n",
      "distance                           1600\n",
      "average_hours                      1600\n",
      "origin_temp                        1600\n",
      "origin_wind_speed                  1600\n",
      "origin_description                12265\n",
      "origin_precip                      1600\n",
      "origin_humidity                    1600\n",
      "origin_visibility                  1600\n",
      "origin_pressure                    1600\n",
      "destination_temp                   1600\n",
      "destination_wind_speed             1600\n",
      "destination_description           12265\n",
      "destination_precip                 1600\n",
      "destination_humidity               1600\n",
      "destination_visibility             1600\n",
      "destination_pressure               1600\n",
      "avg_no_of_vehicles                 1607\n",
      "accident                           1600\n",
      "load_capacity_pounds                659\n",
      "fuel_type                           659\n",
      "name                                848\n",
      "gender                              848\n",
      "age                                 848\n",
      "experience                          848\n",
      "driving_style                       848\n",
      "ratings                             848\n",
      "vehicle_no                          848\n",
      "average_speed_mph                   848\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "truck_id                                   int64\n",
       "route_id                                  object\n",
       "departure_date                    datetime64[ns]\n",
       "estimated_arrival                 datetime64[ns]\n",
       "delay                                      int64\n",
       "route_avg_temp                           float64\n",
       "route_avg_wind_speed                     float64\n",
       "route_avg_precip                         float64\n",
       "route_avg_humidity                       float64\n",
       "route_avg_visibility                     float64\n",
       "route_avg_pressure                       float64\n",
       "route_description                         object\n",
       "estimated_arrival_nearest_hour    datetime64[ns]\n",
       "departure_date_nearest_hour       datetime64[ns]\n",
       "origin_id                                 object\n",
       "destination_id                            object\n",
       "distance                                 float64\n",
       "average_hours                            float64\n",
       "origin_temp                              float64\n",
       "origin_wind_speed                        float64\n",
       "origin_description                        object\n",
       "origin_precip                            float64\n",
       "origin_humidity                          float64\n",
       "origin_visibility                        float64\n",
       "origin_pressure                          float64\n",
       "destination_temp                         float64\n",
       "destination_wind_speed                   float64\n",
       "destination_description                   object\n",
       "destination_precip                       float64\n",
       "destination_humidity                     float64\n",
       "destination_visibility                   float64\n",
       "destination_pressure                     float64\n",
       "avg_no_of_vehicles                       float64\n",
       "accident                                 float64\n",
       "truck_age                                  int64\n",
       "load_capacity_pounds                     float64\n",
       "mileage_mpg                                int64\n",
       "fuel_type                                 object\n",
       "driver_id                                 object\n",
       "name                                      object\n",
       "gender                                    object\n",
       "age                                      float64\n",
       "experience                               float64\n",
       "driving_style                             object\n",
       "ratings                                  float64\n",
       "vehicle_no                               float64\n",
       "average_speed_mph                        float64\n",
       "is_midnight                                int64\n",
       "unique_id                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "null_counts = final_merged_df.isnull().sum()\n",
    "print(null_counts[null_counts > 0])\n",
    "final_merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 49)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "#For numerical columns, you might fill with the mean or median\n",
    "numerical_cols = final_merged_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Fill with mean\n",
    "final_merged_df[numerical_cols] = final_merged_df[numerical_cols].fillna(final_merged_df[numerical_cols].mean())\n",
    "\n",
    "\n",
    "# # For numerical features, use mean imputation\n",
    "# num_imputer = SimpleImputer(strategy='mean')\n",
    "# final_merged_df[['distance', 'average_hours', 'origin_temp', 'origin_wind_speed']] = num_imputer.fit_transform(\n",
    "#     final_merged_df[['distance', 'average_hours', 'origin_temp', 'origin_wind_speed']]\n",
    "# )\n",
    "\n",
    "# For categorical features, use mode imputation\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "final_merged_df[['fuel_type', 'name', 'gender']] = cat_imputer.fit_transform(\n",
    "    final_merged_df[['fuel_type', 'name', 'gender']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values in the 'age' column with the median\n",
    "final_merged_df['age'].fillna(final_merged_df['age'].median(), inplace=True)\n",
    "\n",
    "# Verify that there are no more null values in the 'age' column\n",
    "print(final_merged_df['age'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Imputation for numerical features\n",
    "numerical_features = [\n",
    "    'origin_precip', 'origin_humidity', 'origin_visibility', 'origin_pressure',\n",
    "    'destination_temp', 'destination_wind_speed', 'destination_precip', \n",
    "    'destination_humidity', 'destination_visibility', 'destination_pressure', \n",
    "    'avg_no_of_vehicles', 'accident', 'load_capacity_pounds', 'average_speed_mph'\n",
    "]\n",
    "num_imputer = SimpleImputer(strategy='mean')  # or use 'median' if preferred\n",
    "final_merged_df[numerical_features] = num_imputer.fit_transform(final_merged_df[numerical_features])\n",
    "\n",
    "# Imputation for categorical features\n",
    "categorical_features = [\n",
    "    'fuel_type', 'name', 'gender', 'experience', \n",
    "    'driving_style', 'ratings', 'vehicle_no'\n",
    "]\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "final_merged_df[categorical_features] = cat_imputer.fit_transform(final_merged_df[categorical_features])\n",
    "\n",
    "# For the high missing columns, if you're keeping them, you might need a separate approach\n",
    "# final_merged_df['estimated_arrival_nearest_hour'] = ... (use model predictions or other techniques)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truck_id                              0\n",
       "route_id                              0\n",
       "departure_date                        0\n",
       "estimated_arrival                     0\n",
       "delay                                 0\n",
       "route_avg_temp                        0\n",
       "route_avg_wind_speed                  0\n",
       "route_avg_precip                      0\n",
       "route_avg_humidity                    0\n",
       "route_avg_visibility                  0\n",
       "route_avg_pressure                    0\n",
       "route_description                     0\n",
       "estimated_arrival_nearest_hour    12265\n",
       "departure_date_nearest_hour       12265\n",
       "origin_id                             0\n",
       "destination_id                        0\n",
       "distance                              0\n",
       "average_hours                         0\n",
       "origin_temp                           0\n",
       "origin_wind_speed                     0\n",
       "origin_description                12265\n",
       "origin_precip                         0\n",
       "origin_humidity                       0\n",
       "origin_visibility                     0\n",
       "origin_pressure                       0\n",
       "destination_temp                      0\n",
       "destination_wind_speed                0\n",
       "destination_description           12265\n",
       "destination_precip                    0\n",
       "destination_humidity                  0\n",
       "destination_visibility                0\n",
       "destination_pressure                  0\n",
       "avg_no_of_vehicles                    0\n",
       "accident                              0\n",
       "truck_age                             0\n",
       "load_capacity_pounds                  0\n",
       "mileage_mpg                           0\n",
       "fuel_type                           659\n",
       "driver_id                             0\n",
       "name                                848\n",
       "gender                              848\n",
       "age                                   0\n",
       "experience                            0\n",
       "driving_style                       848\n",
       "ratings                               0\n",
       "vehicle_no                            0\n",
       "average_speed_mph                     0\n",
       "is_midnight                           0\n",
       "unique_id                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.isnull().sum()  # Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Assuming 'categorical_columns' is a list of your categorical features\n",
    "categorical_columns = ['fuel_type', 'name', 'gender', 'driving_style']\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Only apply KNN imputer to numeric representations of categorical variables\n",
    "# Transform categorical variables to numerical codes if needed\n",
    "final_merged_df[categorical_columns] = final_merged_df[categorical_columns].apply(lambda col: col.astype('category').cat.codes)\n",
    "\n",
    "# Fit and transform\n",
    "final_merged_df[categorical_columns] = imputer.fit_transform(final_merged_df[categorical_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated_arrival_nearest_hour    12265\n",
      "departure_date_nearest_hour       12265\n",
      "origin_description                12265\n",
      "destination_description           12265\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_counts_after = final_merged_df.isnull().sum()\n",
    "print(null_counts_after[null_counts_after > 0])\n",
    "null_counts_after.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation for categorical columns\n",
    "final_merged_df['origin_description'].fillna(final_merged_df['origin_description'].mean(), inplace=True)\n",
    "final_merged_df['destination_description'].fillna(final_merged_df['destination_description'].mean(), inplace=True)\n",
    "final_merged_df['estimated_arrival_nearest_hour'].fillna(final_merged_df['estimated_arrival_nearest_hour'].mean(), inplace=True)\n",
    "final_merged_df['departure_date_nearest_hour'].fillna(final_merged_df['departure_date_nearest_hour'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truck_id                                   int64\n",
       "route_id                                  object\n",
       "departure_date                    datetime64[ns]\n",
       "estimated_arrival                 datetime64[ns]\n",
       "delay                                      int64\n",
       "route_avg_temp                           float64\n",
       "route_avg_wind_speed                     float64\n",
       "route_avg_precip                         float64\n",
       "route_avg_humidity                       float64\n",
       "route_avg_visibility                     float64\n",
       "route_avg_pressure                       float64\n",
       "route_description                         object\n",
       "estimated_arrival_nearest_hour    datetime64[ns]\n",
       "departure_date_nearest_hour       datetime64[ns]\n",
       "origin_id                                 object\n",
       "destination_id                            object\n",
       "distance                                 float64\n",
       "average_hours                            float64\n",
       "origin_temp                              float64\n",
       "origin_wind_speed                        float64\n",
       "origin_description                       float64\n",
       "origin_precip                            float64\n",
       "origin_humidity                          float64\n",
       "origin_visibility                        float64\n",
       "origin_pressure                          float64\n",
       "destination_temp                         float64\n",
       "destination_wind_speed                   float64\n",
       "destination_description                  float64\n",
       "destination_precip                       float64\n",
       "destination_humidity                     float64\n",
       "destination_visibility                   float64\n",
       "destination_pressure                     float64\n",
       "avg_no_of_vehicles                       float64\n",
       "accident                                 float64\n",
       "truck_age                                  int64\n",
       "load_capacity_pounds                     float64\n",
       "mileage_mpg                                int64\n",
       "fuel_type                                float64\n",
       "driver_id                                 object\n",
       "name                                     float64\n",
       "gender                                   float64\n",
       "age                                      float64\n",
       "experience                                object\n",
       "driving_style                            float64\n",
       "ratings                                   object\n",
       "vehicle_no                                object\n",
       "average_speed_mph                        float64\n",
       "is_midnight                                int64\n",
       "unique_id                                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 49)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filling missing numerical values with mean\n",
    "# numerical_cols = ['estimated_arrival_nearest_hour', 'departure_date_nearest_hour', \n",
    "#                   'origin_description', 'destination_description']\n",
    "\n",
    "# final_merged_df[numerical_cols] = final_merged_df[numerical_cols].fillna(final_merged_df[numerical_cols].mean())\n",
    "\n",
    "# # Filling missing categorical values with 'Unknown'\n",
    "# categorical_cols = ['origin_description', 'destination_description', 'fuel_type']\n",
    "\n",
    "# final_merged_df[categorical_cols] = final_merged_df[categorical_cols].fillna('Unknown')\n",
    "\n",
    "# # Check the updated DataFrame for null values\n",
    "# print(final_merged_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filling remaining numerical values with 0\n",
    "# remaining_numerical_cols = ['estimated_arrival_nearest_hour', 'departure_date_nearest_hour', \n",
    "#                              'origin_id', 'destination_id', 'distance', 'average_hours', \n",
    "#                              'origin_temp', 'origin_wind_speed', 'origin_precip', \n",
    "#                              'origin_humidity', 'origin_visibility', 'origin_pressure', \n",
    "#                              'destination_temp', 'destination_wind_speed', 'destination_precip', \n",
    "#                              'destination_humidity', 'destination_visibility', \n",
    "#                              'destination_pressure', 'avg_no_of_vehicles', 'accident']\n",
    "\n",
    "# final_merged_df[remaining_numerical_cols] = final_merged_df[remaining_numerical_cols].fillna(0)\n",
    "\n",
    "# # Check the updated DataFrame for null values\n",
    "# print(final_merged_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truck_id                              0\n",
       "route_id                              0\n",
       "departure_date                        0\n",
       "estimated_arrival                     0\n",
       "delay                                 0\n",
       "route_avg_temp                        0\n",
       "route_avg_wind_speed                  0\n",
       "route_avg_precip                      0\n",
       "route_avg_humidity                    0\n",
       "route_avg_visibility                  0\n",
       "route_avg_pressure                    0\n",
       "route_description                     0\n",
       "estimated_arrival_nearest_hour    12265\n",
       "departure_date_nearest_hour       12265\n",
       "origin_id                             0\n",
       "destination_id                        0\n",
       "distance                              0\n",
       "average_hours                         0\n",
       "origin_temp                           0\n",
       "origin_wind_speed                     0\n",
       "origin_description                12265\n",
       "origin_precip                         0\n",
       "origin_humidity                       0\n",
       "origin_visibility                     0\n",
       "origin_pressure                       0\n",
       "destination_temp                      0\n",
       "destination_wind_speed                0\n",
       "destination_description           12265\n",
       "destination_precip                    0\n",
       "destination_humidity                  0\n",
       "destination_visibility                0\n",
       "destination_pressure                  0\n",
       "avg_no_of_vehicles                    0\n",
       "accident                              0\n",
       "truck_age                             0\n",
       "load_capacity_pounds                  0\n",
       "mileage_mpg                           0\n",
       "fuel_type                             0\n",
       "driver_id                             0\n",
       "name                                  0\n",
       "gender                                0\n",
       "age                                   0\n",
       "experience                            0\n",
       "driving_style                         0\n",
       "ratings                               0\n",
       "vehicle_no                            0\n",
       "average_speed_mph                     0\n",
       "is_midnight                           0\n",
       "unique_id                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.isnull().sum()  # Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['truck_id', 'route_id', 'departure_date', 'estimated_arrival', 'delay',\n",
       "       'route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip',\n",
       "       'route_avg_humidity', 'route_avg_visibility', 'route_avg_pressure',\n",
       "       'route_description', 'estimated_arrival_nearest_hour',\n",
       "       'departure_date_nearest_hour', 'origin_id', 'destination_id',\n",
       "       'distance', 'average_hours', 'origin_temp', 'origin_wind_speed',\n",
       "       'origin_description', 'origin_precip', 'origin_humidity',\n",
       "       'origin_visibility', 'origin_pressure', 'destination_temp',\n",
       "       'destination_wind_speed', 'destination_description',\n",
       "       'destination_precip', 'destination_humidity', 'destination_visibility',\n",
       "       'destination_pressure', 'avg_no_of_vehicles', 'accident', 'truck_age',\n",
       "       'load_capacity_pounds', 'mileage_mpg', 'fuel_type', 'driver_id', 'name',\n",
       "       'gender', 'age', 'experience', 'driving_style', 'ratings', 'vehicle_no',\n",
       "       'average_speed_mph', 'is_midnight', 'unique_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Missing Values:\n",
      " estimated_arrival_nearest_hour    12265\n",
      "departure_date_nearest_hour       12265\n",
      "origin_description                12265\n",
      "destination_description           12265\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4. Recheck for any remaining missing values (optional)\n",
    "remaining_missing = final_merged_df.isnull().sum()\n",
    "print(\"Remaining Missing Values:\\n\", remaining_missing[remaining_missing > 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12265, 49)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck_id                                   int64\n",
      "route_id                                  object\n",
      "departure_date                    datetime64[ns]\n",
      "estimated_arrival                 datetime64[ns]\n",
      "delay                                      int64\n",
      "route_avg_temp                           float64\n",
      "route_avg_wind_speed                     float64\n",
      "route_avg_precip                         float64\n",
      "route_avg_humidity                       float64\n",
      "route_avg_visibility                     float64\n",
      "route_avg_pressure                       float64\n",
      "route_description                         object\n",
      "estimated_arrival_nearest_hour    datetime64[ns]\n",
      "departure_date_nearest_hour       datetime64[ns]\n",
      "origin_id                                 object\n",
      "destination_id                            object\n",
      "distance                                 float64\n",
      "average_hours                            float64\n",
      "origin_temp                              float64\n",
      "origin_wind_speed                        float64\n",
      "origin_description                       float64\n",
      "origin_precip                            float64\n",
      "origin_humidity                          float64\n",
      "origin_visibility                        float64\n",
      "origin_pressure                          float64\n",
      "destination_temp                         float64\n",
      "destination_wind_speed                   float64\n",
      "destination_description                  float64\n",
      "destination_precip                       float64\n",
      "destination_humidity                     float64\n",
      "destination_visibility                   float64\n",
      "destination_pressure                     float64\n",
      "avg_no_of_vehicles                       float64\n",
      "accident                                 float64\n",
      "truck_age                                  int64\n",
      "load_capacity_pounds                     float64\n",
      "mileage_mpg                                int64\n",
      "fuel_type                                float64\n",
      "driver_id                                 object\n",
      "name                                     float64\n",
      "gender                                   float64\n",
      "age                                      float64\n",
      "experience                                object\n",
      "driving_style                            float64\n",
      "ratings                                   object\n",
      "vehicle_no                                object\n",
      "average_speed_mph                        float64\n",
      "is_midnight                                int64\n",
      "unique_id                                  int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check data types of all columns\n",
    "print(final_merged_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truck_id                                   int64\n",
      "route_id                                  object\n",
      "departure_date                    datetime64[ns]\n",
      "estimated_arrival                 datetime64[ns]\n",
      "delay                                      int64\n",
      "route_avg_temp                           float64\n",
      "route_avg_wind_speed                     float64\n",
      "route_avg_precip                         float64\n",
      "route_avg_humidity                       float64\n",
      "route_avg_visibility                     float64\n",
      "route_avg_pressure                       float64\n",
      "route_description                         object\n",
      "estimated_arrival_nearest_hour    datetime64[ns]\n",
      "departure_date_nearest_hour       datetime64[ns]\n",
      "origin_id                                 object\n",
      "destination_id                            object\n",
      "distance                                 float64\n",
      "average_hours                            float64\n",
      "origin_temp                              float64\n",
      "origin_wind_speed                        float64\n",
      "origin_description                        object\n",
      "origin_precip                            float64\n",
      "origin_humidity                          float64\n",
      "origin_visibility                        float64\n",
      "origin_pressure                          float64\n",
      "destination_temp                         float64\n",
      "destination_wind_speed                   float64\n",
      "destination_description                   object\n",
      "destination_precip                       float64\n",
      "destination_humidity                     float64\n",
      "destination_visibility                   float64\n",
      "destination_pressure                     float64\n",
      "avg_no_of_vehicles                       float64\n",
      "accident                                 float64\n",
      "truck_age                                  int64\n",
      "load_capacity_pounds                     float64\n",
      "mileage_mpg                                int64\n",
      "fuel_type                                 object\n",
      "driver_id                                 object\n",
      "name                                      object\n",
      "gender                                    object\n",
      "age                                      float64\n",
      "experience                                object\n",
      "driving_style                             object\n",
      "ratings                                   object\n",
      "vehicle_no                                object\n",
      "average_speed_mph                        float64\n",
      "is_midnight                                int64\n",
      "unique_id                                  int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Correcting the types of the categorical columns\n",
    "categorical_cols = [\n",
    "    'origin_description',\n",
    "    'destination_description',\n",
    "    'fuel_type',\n",
    "    'name',\n",
    "    'gender',\n",
    "    'experience',\n",
    "    'driving_style',\n",
    "    'ratings',\n",
    "    'vehicle_no'\n",
    "]\n",
    "\n",
    "for col in categorical_cols:\n",
    "    final_merged_df[col] = final_merged_df[col].astype('object')\n",
    "\n",
    "# Optional: Verify the data types again\n",
    "print(final_merged_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test_validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Get the current UTC time\n",
    "current_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "\n",
    "# Convert estimated_arrival and departure_date to timezone-aware datetime\n",
    "final_merged_df['estimated_arrival'] = pd.to_datetime(final_merged_df['estimated_arrival'], utc=True)\n",
    "final_merged_df['departure_date'] = pd.to_datetime(final_merged_df['departure_date'], utc=True)\n",
    "\n",
    "# Define the training, validation, and test datasets based on today's date\n",
    "train_df = final_merged_df[final_merged_df['estimated_arrival'] <= current_time]\n",
    "validation_df = final_merged_df[(final_merged_df['estimated_arrival'] > current_time) & \n",
    "                                 (final_merged_df['estimated_arrival'] <= current_time + pd.Timedelta(days=7))]\n",
    "test_df = final_merged_df[final_merged_df['estimated_arrival'] > current_time + pd.Timedelta(days=7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Get the current UTC time\n",
    "current_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "\n",
    "# Convert estimated_arrival and departure_date to timezone-aware datetime\n",
    "final_merged_df['estimated_arrival'] = pd.to_datetime(final_merged_df['estimated_arrival'], utc=True)\n",
    "final_merged_df['departure_date'] = pd.to_datetime(final_merged_df['departure_date'], utc=True)\n",
    "\n",
    "# Define the training, validation, and test datasets based on the current date\n",
    "train_df = final_merged_df[final_merged_df['estimated_arrival'] <= current_time]\n",
    "validation_df = final_merged_df[(final_merged_df['estimated_arrival'] > current_time) & \n",
    "                                 (final_merged_df['estimated_arrival'] <= current_time + pd.Timedelta(days=7))]\n",
    "test_df = final_merged_df[final_merged_df['estimated_arrival'] > current_time + pd.Timedelta(days=7)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum estimated_arrival: 2019-01-01 07:04:48+00:00\n",
      "Maximum estimated_arrival: 2019-02-14 16:06:00+00:00\n",
      "Current UTC time: 2024-10-19 23:23:13.838043+00:00\n",
      "Total rows in final_merged_df: 12265\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum estimated_arrival:\", final_merged_df['estimated_arrival'].min())\n",
    "print(\"Maximum estimated_arrival:\", final_merged_df['estimated_arrival'].max())\n",
    "print(\"Current UTC time:\", current_time)\n",
    "print(\"Total rows in final_merged_df:\", final_merged_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming final_merged_df is already defined\n",
    "\n",
    "# Step 1: Define total rows\n",
    "total_rows = len(final_merged_df)\n",
    "\n",
    "# Step 2: Calculate the number of training, validation, and testing samples\n",
    "train_size = int(total_rows * 0.7)    # 70%\n",
    "validation_size = int(total_rows * 0.1) # 10%\n",
    "test_size = total_rows - (train_size + validation_size)  # 20%\n",
    "\n",
    "# Step 3: Shuffle the data\n",
    "shuffled_df = final_merged_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split the data into training, validation, and testing sets\n",
    "train_df = shuffled_df.iloc[:train_size]\n",
    "validation_df = shuffled_df.iloc[train_size:train_size + validation_size]\n",
    "test_df = shuffled_df.iloc[train_size + validation_size:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define features and target\n",
    "cts_cols = ['route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip', \n",
    "            'route_avg_humidity', 'route_avg_visibility', 'route_avg_pressure', \n",
    "            'distance', 'average_hours', 'origin_temp', 'origin_wind_speed', \n",
    "            'origin_precip', 'origin_humidity', 'origin_visibility', \n",
    "            'origin_pressure', 'destination_temp', 'destination_wind_speed', \n",
    "            'destination_precip', 'destination_humidity', 'destination_visibility', \n",
    "            'destination_pressure', 'avg_no_of_vehicles', 'truck_age', \n",
    "            'load_capacity_pounds', 'mileage_mpg', 'age', 'experience', \n",
    "            'average_speed_mph']\n",
    "\n",
    "cat_cols = ['route_description', 'fuel_type', 'gender', \n",
    "            'driving_style', 'ratings', 'is_midnight']\n",
    "\n",
    "target = 'delay'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Splitting features and target variable\n",
    "X_train = train_df[cts_cols + cat_cols]\n",
    "y_train = train_df[target]\n",
    "\n",
    "X_valid = validation_df[cts_cols + cat_cols]\n",
    "y_valid = validation_df[target]\n",
    "\n",
    "X_test = test_df[cts_cols + cat_cols]\n",
    "y_test = test_df[target]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (8585, 33) (8585,)\n",
      "Validation set shape: (1226, 33) (1226,)\n",
      "Test set shape: (2454, 33) (2454,)\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Output the shapes to confirm\n",
    "print(\"Train set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_valid.shape, y_valid.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "encoding and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define categorical and numerical columns\n",
    "encoder_columns = cat_cols  # Categorical features\n",
    "scaler_columns = cts_cols    # Continuous features\n",
    "\n",
    "# Step 1: One-hot encoding for categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, drop='first', handle_unknown='ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Standard scaling for continuous features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, scaler_columns),\n",
    "        ('cat', encoder, encoder_columns)\n",
    "    ],\n",
    "    remainder='drop'  # Drop any other columns not specified\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Fit and transform the training data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Transform validation and test data using the same preprocessor\n",
    "X_valid_transformed = preprocessor.transform(X_valid)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Now X_train_transformed, X_valid_transformed, and X_test_transformed are ready for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8585, 86)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['truck_id', 'route_id', 'departure_date', 'estimated_arrival', 'delay',\n",
      "       'route_avg_temp', 'route_avg_wind_speed', 'route_avg_precip',\n",
      "       'route_avg_humidity', 'route_avg_visibility', 'route_avg_pressure',\n",
      "       'route_description', 'estimated_arrival_nearest_hour',\n",
      "       'departure_date_nearest_hour', 'origin_id', 'destination_id',\n",
      "       'distance', 'average_hours', 'origin_temp', 'origin_wind_speed',\n",
      "       'origin_description', 'origin_precip', 'origin_humidity',\n",
      "       'origin_visibility', 'origin_pressure', 'destination_temp',\n",
      "       'destination_wind_speed', 'destination_description',\n",
      "       'destination_precip', 'destination_humidity', 'destination_visibility',\n",
      "       'destination_pressure', 'avg_no_of_vehicles', 'accident', 'truck_age',\n",
      "       'load_capacity_pounds', 'mileage_mpg', 'fuel_type', 'driver_id', 'name',\n",
      "       'gender', 'age', 'experience', 'driving_style', 'ratings', 'vehicle_no',\n",
      "       'average_speed_mph', 'is_midnight', 'unique_id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(final_merged_df.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Set Up MLflow for Model Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build model with mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mlflow in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.17.0)\n",
      "Requirement already satisfied: mlflow-skinny==2.17.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (2.17.0)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (3.0.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (1.13.3)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (3.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: matplotlib<4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (3.9.2)\n",
      "Requirement already satisfied: numpy<3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (1.26.4)\n",
      "Requirement already satisfied: pandas<3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (2.1.4)\n",
      "Requirement already satisfied: pyarrow<18,>=4.0.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (17.0.0)\n",
      "Requirement already satisfied: scikit-learn<2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (1.5.1)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (1.14.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (1.4.48)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (8.1.7)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (0.34.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (3.1.43)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (8.4.0)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (1.27.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (1.27.0)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (24.1)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (4.25.4)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from mlflow-skinny==2.17.0->mlflow) (0.5.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from docker<8,>=4.0.0->mlflow) (306)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from docker<8,>=4.0.0->mlflow) (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Flask<4->mlflow) (3.0.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Flask<4->mlflow) (1.8.2)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from graphene<4->mlflow) (3.2.5)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from graphene<4->mlflow) (9.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Jinja2<4,>=3.0->mlflow) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib<4->mlflow) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib<4->mlflow) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib<4->mlflow) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib<4->mlflow) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib<4->mlflow) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib<4->mlflow) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from matplotlib<4->mlflow) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas<3->mlflow) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from click<9,>=7.0->mlflow-skinny==2.17.0->mlflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (2.35.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (4.0.11)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from importlib-metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.17.0->mlflow) (3.20.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (0.48b0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.7->matplotlib<4->mlflow) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (3.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.17.0->mlflow) (2024.8.30)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.17.0->mlflow) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.17.0->mlflow) (5.0.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\anucv\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.17.0->mlflow) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define Your Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you already have X_train_transformed, y_train, X_valid_transformed, y_valid\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train and Evaluate Each Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic regression- with mlflow and hopswork model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       813\n",
      "           1       0.64      0.62      0.63       413\n",
      "\n",
      "    accuracy                           0.76      1226\n",
      "   macro avg       0.73      0.72      0.72      1226\n",
      "weighted avg       0.75      0.76      0.76      1226\n",
      "\n",
      "Train Score: 0.7380314502038439\n",
      "Validation/Test Score: 0.7561174551386624\n",
      "2024-10-19 19:24:11,423 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/19 19:24:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: b499ecfc56c348e396b698f22c8bc74d\n",
      "MLflow Link: http://127.0.0.1:5000/#/experiments/0/runs/b499ecfc56c348e396b698f22c8bc74d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ddd3b7363f14925883e02308bfe42a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e19ac9ceebed4cf08e70437df8e59303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/1551 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/19 19:24:21 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run welcoming-mare-39 at: http://127.0.0.1:5000/#/experiments/0/runs/b499ecfc56c348e396b698f22c8bc74d.\n",
      "2024/10/19 19:24:21 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1104021/models/Logistic_Regression_Model/1\n",
      "Model saved and registered in Hopsworks successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import hsml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Establish a connection to Hopsworks using host, project name, and API key\n",
    "connection = hsml.connection(\n",
    "    host=\"c.app.hopsworks.ai\",  # Your Hopsworks instance URL\n",
    "    project=\"ML_truckdelay\",  # Correct project name from Hopsworks\n",
    "    api_key_value=\"8ViXMBkcrCAUFm4Y.PEDm3J6NPoMDtf2L7MpnYsCdElsDMCPRr1RI3vbPtLnjogWE1f6hdKOoxpQbxrM0\"\n",
    ")\n",
    "\n",
    "# Access the model registry\n",
    "mr = connection.get_model_registry()\n",
    "\n",
    "# Set MLflow tracking URI (update if MLflow is hosted remotely)\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Step 2: Start MLflow run and train the Logistic Regression model\n",
    "with mlflow.start_run() as run:\n",
    "    # Step 3: Initialize and train the Logistic Regression model\n",
    "    log_reg = LogisticRegression(max_iter=1000)\n",
    "    log_reg.fit(X_train_transformed, y_train)\n",
    "\n",
    "    # Make predictions on validation set\n",
    "    y_pred_log_reg = log_reg.predict(X_valid_transformed)\n",
    "\n",
    "    # Step 4: Evaluate the model\n",
    "    print(\"Logistic Regression Classification Report:\")\n",
    "    print(classification_report(y_valid, y_pred_log_reg))\n",
    "\n",
    "    # Calculate accuracy scores\n",
    "    train_score = accuracy_score(y_train, log_reg.predict(X_train_transformed))\n",
    "    test_score = accuracy_score(y_valid, y_pred_log_reg)\n",
    "\n",
    "    print(f\"Train Score: {train_score}\")\n",
    "    print(f\"Validation/Test Score: {test_score}\")\n",
    "\n",
    "    # Step 5: Log model and parameters in MLflow\n",
    "    mlflow.sklearn.log_model(log_reg, \"Logistic_Regression_Model\")\n",
    "    mlflow.log_params({\"model\": \"Logistic Regression\", \"max_iter\": 1000})\n",
    "    mlflow.log_metrics({\"train_score\": train_score, \"test_score\": test_score})\n",
    "\n",
    "    # Get MLflow run details\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "    print(f\"MLflow Link: http://127.0.0.1:5000/#/experiments/{experiment_id}/runs/{run_id}\")\n",
    "\n",
    "    # Step 6: Save the model locally\n",
    "    model_path = '/tmp/logistic_regression_model.pkl'\n",
    "    joblib.dump(log_reg, model_path)\n",
    "\n",
    "    # Step 7: Register the model in Hopsworks Model Registry\n",
    "    model = mr.sklearn.create_model(\n",
    "        name=\"Logistic_Regression_Model\",\n",
    "        version=1,  # Version of the model\n",
    "        metrics={\"train_score\": train_score, \"validation_score\": test_score},\n",
    "        description=\"Logistic Regression Model for Truck Delay Classification\"\n",
    "    )\n",
    "\n",
    "    # Save the model to the registry\n",
    "    model.save(model_path)\n",
    "\n",
    "    print(\"Model saved and registered in Hopsworks successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter tuning - logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Tuned Logistic Regression Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.82       813\n",
      "           1       0.66      0.60      0.63       413\n",
      "\n",
      "    accuracy                           0.76      1226\n",
      "   macro avg       0.73      0.72      0.72      1226\n",
      "weighted avg       0.76      0.76      0.76      1226\n",
      "\n",
      "Precision: 0.66\n",
      "Recall: 0.60\n",
      "F1 Score: 0.63\n",
      "2024-10-19 19:37:55,294 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07fcae7fe3564fd09c38ba3773a2326e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: c9b52066dc36478599bc2319d4bed59d\n",
      "MLflow Link: http://127.0.0.1:5000/#/experiments/0/runs/c9b52066dc36478599bc2319d4bed59d\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0ca492836a42729d745548df467ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a749e9e6f34e24aeabdd9d23d0edeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/1551 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/19 19:38:05 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run delightful-vole-998 at: http://127.0.0.1:5000/#/experiments/0/runs/c9b52066dc36478599bc2319d4bed59d.\n",
      "2024/10/19 19:38:05 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1104021/models/Tuned_Logistic_Regression_Model/1\n",
      "Tuned model saved and registered in Hopsworks successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import hsml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Establish a connection to Hopsworks using host, project name, and API key\n",
    "connection = hsml.connection(\n",
    "    host=\"c.app.hopsworks.ai\",  # Your Hopsworks instance URL\n",
    "    project=\"ML_truckdelay\",  # Correct project name from Hopsworks\n",
    "    api_key_value=\"8ViXMBkcrCAUFm4Y.PEDm3J6NPoMDtf2L7MpnYsCdElsDMCPRr1RI3vbPtLnjogWE1f6hdKOoxpQbxrM0\"\n",
    ")\n",
    "\n",
    "# Access the model registry\n",
    "mr = connection.get_model_registry()\n",
    "\n",
    "# Set MLflow tracking URI (update if MLflow is hosted remotely)\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Ensure previous run is ended\n",
    "mlflow.end_run()  \n",
    "\n",
    "# Step 2: Start MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Define parameter grid for hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],  \n",
    "        'penalty': ['l1', 'l2'],       \n",
    "        'solver': ['liblinear', 'saga']  \n",
    "    }\n",
    "\n",
    "    # Initialize GridSearchCV\n",
    "    grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    # Fit on training data\n",
    "    grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "    # Get the best model\n",
    "    best_log_reg = grid_search.best_estimator_\n",
    "\n",
    "    # Evaluate the tuned model on validation set\n",
    "    y_pred_best = best_log_reg.predict(X_valid_transformed)\n",
    "\n",
    "    # Print the classification report\n",
    "    print(\"Tuned Logistic Regression Classification Report:\")\n",
    "    print(classification_report(y_valid, y_pred_best))\n",
    "\n",
    "    # Calculate precision, recall, and F1-score\n",
    "    precision = precision_score(y_valid, y_pred_best)\n",
    "    recall = recall_score(y_valid, y_pred_best)\n",
    "    f1 = f1_score(y_valid, y_pred_best)\n",
    "\n",
    "    # Print calculated metrics\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "    # Create a valid input example with the correct number of features\n",
    "    input_example = np.random.rand(1, 86)  # Example with 86 random features\n",
    "\n",
    "    # Log the tuned model in MLflow with the valid input example\n",
    "    mlflow.sklearn.log_model(best_log_reg, \"Tuned_Logistic_Regression_Model\", input_example=input_example)\n",
    "\n",
    "    # Log the parameters and metrics\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    mlflow.log_metric(\"test_score_tuned\", accuracy_score(y_valid, y_pred_best))\n",
    "    mlflow.log_metric(\"train_score_tuned\", accuracy_score(y_train, best_log_reg.predict(X_train_transformed)))\n",
    "\n",
    "    # Log additional metrics\n",
    "    mlflow.log_metric(\"precision_tuned\", precision)\n",
    "    mlflow.log_metric(\"recall_tuned\", recall)\n",
    "    mlflow.log_metric(\"f1_score_tuned\", f1)\n",
    "\n",
    "    # Get MLflow run details\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "    print(f\"MLflow Link: http://127.0.0.1:5000/#/experiments/{experiment_id}/runs/{run_id}\")\n",
    "\n",
    "    # Step 6: Save the model locally\n",
    "    model_path = '/tmp/tuned_logistic_regression_model.pkl'\n",
    "    joblib.dump(best_log_reg, model_path)\n",
    "\n",
    "    # Step 7: Register the model in Hopsworks Model Registry\n",
    "    model = mr.sklearn.create_model(\n",
    "        name=\"Tuned_Logistic_Regression_Model\",\n",
    "        version=1,  # Version of the model\n",
    "        metrics={\"train_score\": accuracy_score(y_train, best_log_reg.predict(X_train_transformed)), \n",
    "                  \"validation_score\": accuracy_score(y_valid, y_pred_best)},\n",
    "        description=\"Tuned Logistic Regression Model for Truck Delay Classification\"\n",
    "    )\n",
    "\n",
    "    # Save the model to the registry\n",
    "    model.save(model_path)\n",
    "\n",
    "    print(\"Tuned model saved and registered in Hopsworks successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randome Forest with Hopsworks Model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       813\n",
      "           1       0.78      0.58      0.66       413\n",
      "\n",
      "    accuracy                           0.80      1226\n",
      "   macro avg       0.79      0.75      0.76      1226\n",
      "weighted avg       0.80      0.80      0.79      1226\n",
      "\n",
      "Train Score (Accuracy): 0.9999\n",
      "Validation/Test Score (Accuracy): 0.8010\n",
      "2024-10-19 20:14:55,468 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2be17cbe8b4451590355630e35be026",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Model Accuracy (Validation/Test): 0.8010\n",
      "MLflow Run ID: 272c47e6b5e2493fb408b126a185a86e\n",
      "MLflow Link: http://127.0.0.1:5000/#/experiments/0/runs/272c47e6b5e2493fb408b126a185a86e\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f859e005619d4364829d337c55404ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9da91c24dd0d4e78ac19f29b7f1f7ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/24537113 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/19 20:15:38 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run worried-skink-520 at: http://127.0.0.1:5000/#/experiments/0/runs/272c47e6b5e2493fb408b126a185a86e.\n",
      "2024/10/19 20:15:38 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1104021/models/Random_Forest_Model/1\n",
      "Random Forest model saved and registered in Hopsworks successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import hsml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Establish a connection to Hopsworks using host, project name, and API key\n",
    "connection = hsml.connection(\n",
    "    host=\"c.app.hopsworks.ai\",  # Your Hopsworks instance URL\n",
    "    project=\"ML_truckdelay\",  # Correct project name from Hopsworks\n",
    "    api_key_value=\"8ViXMBkcrCAUFm4Y.PEDm3J6NPoMDtf2L7MpnYsCdElsDMCPRr1RI3vbPtLnjogWE1f6hdKOoxpQbxrM0\"\n",
    ")\n",
    "\n",
    "# Access the model registry\n",
    "mr = connection.get_model_registry()\n",
    "\n",
    "# Set MLflow tracking URI (update if MLflow is hosted remotely)\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Step 2: Start MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Initialize and train the Random Forest model\n",
    "    rf_model = RandomForestClassifier(random_state=42)\n",
    "    rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "    # Make predictions on validation set\n",
    "    y_pred_rf = rf_model.predict(X_valid_transformed)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"Random Forest Classification Report:\")\n",
    "    print(classification_report(y_valid, y_pred_rf))\n",
    "\n",
    "    # Calculate and print accuracy scores\n",
    "    train_predictions = rf_model.predict(X_train_transformed)\n",
    "    train_score = accuracy_score(y_train, train_predictions)\n",
    "    test_score = accuracy_score(y_valid, y_pred_rf)\n",
    "\n",
    "    # Additional metrics\n",
    "    precision = precision_score(y_valid, y_pred_rf, average='weighted')\n",
    "    recall = recall_score(y_valid, y_pred_rf, average='weighted')\n",
    "    f1 = f1_score(y_valid, y_pred_rf, average='weighted')\n",
    "\n",
    "    print(f\"Train Score (Accuracy): {train_score:.4f}\")  # Train accuracy\n",
    "    print(f\"Validation/Test Score (Accuracy): {test_score:.4f}\")  # Test accuracy\n",
    "\n",
    "    # Log model and parameters in MLflow\n",
    "    input_example = X_valid_transformed[0:1]  # Use one row from your validation set as an example\n",
    "\n",
    "    # Log the model with an input example\n",
    "    mlflow.sklearn.log_model(rf_model, \"Random_Forest_Model\", input_example=input_example)\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"Random Forest\",\n",
    "        \"train_score\": train_score,\n",
    "        \"test_score\": test_score\n",
    "    })\n",
    "    mlflow.log_metrics({\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"train_accuracy\": train_score,\n",
    "        \"test_accuracy\": test_score\n",
    "    })\n",
    "\n",
    "    # Print overall accuracy of the model (validation/test)\n",
    "    print(f\"Overall Model Accuracy (Validation/Test): {test_score:.4f}\")\n",
    "\n",
    "    # Get the run ID for this run\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id\n",
    "\n",
    "    # Display MLflow link to the run\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "    print(f\"MLflow Link: http://127.0.0.1:5000/#/experiments/{experiment_id}/runs/{run_id}\")\n",
    "\n",
    "    # Step 6: Save the model locally\n",
    "    model_path = '/tmp/random_forest_model.pkl'\n",
    "    joblib.dump(rf_model, model_path)\n",
    "\n",
    "    # Step 7: Register the model in Hopsworks Model Registry\n",
    "    model = mr.sklearn.create_model(\n",
    "        name=\"Random_Forest_Model\",\n",
    "        version=1,  # Version of the model\n",
    "        metrics={\"train_score\": train_score, \"validation_score\": test_score},\n",
    "        description=\"Random Forest Model for Truck Delay Classification\"\n",
    "    )\n",
    "\n",
    "    # Save the model to the registry\n",
    "    model.save(model_path)\n",
    "\n",
    "    print(\"Random Forest model saved and registered in Hopsworks successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Hyperparameter Tuning with Hopsworks Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       813\n",
      "           1       0.78      0.58      0.66       413\n",
      "\n",
      "    accuracy                           0.80      1226\n",
      "   macro avg       0.80      0.75      0.76      1226\n",
      "weighted avg       0.80      0.80      0.79      1226\n",
      "\n",
      "Train Score (Accuracy): 0.9999\n",
      "Validation/Test Score (Accuracy): 0.8034\n",
      "2024-10-19 20:20:30,603 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52857b6615bb46a19decb751cce0bbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: 5f52e819cdd948808bd980601c1239c0\n",
      "MLflow Link: http://127.0.0.1:5000/#/experiments/0/runs/5f52e819cdd948808bd980601c1239c0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17e1d4f7baa4a8b89c17a1082061340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888c38d23e1b472cbc85fff04f2647a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/49174073 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/19 20:21:17 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run popular-dove-971 at: http://127.0.0.1:5000/#/experiments/0/runs/5f52e819cdd948808bd980601c1239c0.\n",
      "2024/10/19 20:21:17 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1104021/models/Tuned_Random_Forest_Model/1\n",
      "Random Forest model saved and registered in Hopsworks successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import hsml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Establish a connection to Hopsworks using host, project name, and API key\n",
    "connection = hsml.connection(\n",
    "    host=\"c.app.hopsworks.ai\",  # Your Hopsworks instance URL\n",
    "    project=\"ML_truckdelay\",  # Correct project name from Hopsworks\n",
    "    api_key_value=\"8ViXMBkcrCAUFm4Y.PEDm3J6NPoMDtf2L7MpnYsCdElsDMCPRr1RI3vbPtLnjogWE1f6hdKOoxpQbxrM0\"\n",
    ")\n",
    "\n",
    "# Access the model registry\n",
    "mr = connection.get_model_registry()\n",
    "\n",
    "# Set MLflow tracking URI (update if MLflow is hosted remotely)\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']  # Updated max_features values\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, scoring='accuracy', \n",
    "                           error_score='raise')\n",
    "\n",
    "# Step 2: Start MLflow run for the grid search\n",
    "with mlflow.start_run() as run:\n",
    "    # Fit the grid search to the training data\n",
    "    grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "    # Get the best model and hyperparameters\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Log the best hyperparameters\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_rf = best_rf_model.predict(X_valid_transformed)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"Random Forest Classification Report:\")\n",
    "    print(classification_report(y_valid, y_pred_rf))\n",
    "\n",
    "    # Calculate and log accuracy scores\n",
    "    train_score = accuracy_score(y_train, best_rf_model.predict(X_train_transformed))\n",
    "    test_score = accuracy_score(y_valid, y_pred_rf)\n",
    "\n",
    "    print(f\"Train Score (Accuracy): {train_score:.4f}\")  # Train accuracy\n",
    "    print(f\"Validation/Test Score (Accuracy): {test_score:.4f}\")  # Test accuracy\n",
    "\n",
    "    # Calculate additional metrics\n",
    "    precision = precision_score(y_valid, y_pred_rf, average='weighted')\n",
    "    recall = recall_score(y_valid, y_pred_rf, average='weighted')\n",
    "    f1 = f1_score(y_valid, y_pred_rf, average='weighted')\n",
    "\n",
    "    # Log the additional metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": train_score,\n",
    "        \"test_accuracy\": test_score,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1\n",
    "    })\n",
    "\n",
    "    # Log model with the best parameters\n",
    "    input_example = X_valid_transformed[0:1]  # Use one row from your validation set as an example\n",
    "    mlflow.sklearn.log_model(best_rf_model, \"Tuned_Random_Forest_Model\", input_example=input_example)\n",
    "\n",
    "    # Get the run ID for this run\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id\n",
    "\n",
    "    # Display MLflow link to the run\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "    print(f\"MLflow Link: http://127.0.0.1:5000/#/experiments/{experiment_id}/runs/{run_id}\")\n",
    "\n",
    "    # Step 3: Save the model locally\n",
    "    model_path = '/tmp/random_forest_model.pkl'\n",
    "    joblib.dump(best_rf_model, model_path)\n",
    "\n",
    "    # Step 4: Register the model in Hopsworks Model Registry\n",
    "    model = mr.sklearn.create_model(\n",
    "        name=\"Tuned_Random_Forest_Model\",\n",
    "        version=1,  # Version of the model\n",
    "        metrics={\"train_score\": train_score, \"validation_score\": test_score},\n",
    "        description=\"Random Forest Model with Hyperparameter Tuning for Truck Delay Classification\"\n",
    "    )\n",
    "\n",
    "    # Save the model to the registry\n",
    "    model.save(model_path)\n",
    "\n",
    "    print(\"Random Forest model saved and registered in Hopsworks successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with hopswork Modle registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       813\n",
      "           1       0.73      0.60      0.65       413\n",
      "\n",
      "    accuracy                           0.79      1226\n",
      "   macro avg       0.77      0.74      0.75      1226\n",
      "weighted avg       0.78      0.79      0.78      1226\n",
      "\n",
      "Validation/Test Accuracy: 0.7879\n",
      "Train Accuracy: 0.9540\n",
      "2024-10-19 20:22:54,933 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5062f355ae474de2af512e1bef219694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: 6bb53ca10fb248ad8b2a40e1c59fb7d3\n",
      "MLflow Link: http://127.0.0.1:5000/#/experiments/0/runs/6bb53ca10fb248ad8b2a40e1c59fb7d3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1520cbf0b89f48a88111251538a61d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62554e214c634b7b9611714f5c6b4915",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/322474 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/19 20:23:06 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run delicate-kit-177 at: http://127.0.0.1:5000/#/experiments/0/runs/6bb53ca10fb248ad8b2a40e1c59fb7d3.\n",
      "2024/10/19 20:23:06 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1104021/models/XGBoost_Model/1\n",
      "XGBoost model saved and registered in Hopsworks successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import hsml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "\n",
    "# Step 1: Establish a connection to Hopsworks using host, project name, and API key\n",
    "connection = hsml.connection(\n",
    "    host=\"c.app.hopsworks.ai\",  # Your Hopsworks instance URL\n",
    "    project=\"ML_truckdelay\",  # Correct project name from Hopsworks\n",
    "    api_key_value=\"8ViXMBkcrCAUFm4Y.PEDm3J6NPoMDtf2L7MpnYsCdElsDMCPRr1RI3vbPtLnjogWE1f6hdKOoxpQbxrM0\"\n",
    ")\n",
    "\n",
    "# Access the model registry\n",
    "mr = connection.get_model_registry()\n",
    "\n",
    "# Set MLflow tracking URI (update if MLflow is hosted remotely)\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Step 2: Start MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Initialize and train the XGBoost model\n",
    "    xgb_model = XGBClassifier(eval_metric='logloss')  # Removed use_label_encoder\n",
    "    xgb_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_xgb = xgb_model.predict(X_valid_transformed)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"XGBoost Classification Report:\")\n",
    "    print(classification_report(y_valid, y_pred_xgb))\n",
    "    \n",
    "    # Calculate accuracy and other metrics\n",
    "    accuracy = accuracy_score(y_valid, y_pred_xgb)\n",
    "    precision = precision_score(y_valid, y_pred_xgb, average='weighted')\n",
    "    recall = recall_score(y_valid, y_pred_xgb, average='weighted')\n",
    "    f1 = f1_score(y_valid, y_pred_xgb, average='weighted')\n",
    "\n",
    "    print(f\"Validation/Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Calculate and log train score\n",
    "    train_predictions = xgb_model.predict(X_train_transformed)\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # Log model, parameters, and metrics in MLflow\n",
    "    input_example = X_valid_transformed[0:1]  # Use one row from your validation set as an example\n",
    "    mlflow.sklearn.log_model(xgb_model, \"XGBoost_Model\", input_example=input_example)  # Add input example\n",
    "\n",
    "    mlflow.log_params({\n",
    "        \"model\": \"XGBoost\",\n",
    "        \"eval_metric\": 'logloss',\n",
    "    })\n",
    "    \n",
    "    # Log the metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"test_accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    })\n",
    "\n",
    "    # Get the run ID for this run\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id\n",
    "\n",
    "    # Display MLflow link to the run\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "    print(f\"MLflow Link: http://127.0.0.1:5000/#/experiments/{experiment_id}/runs/{run_id}\")\n",
    "\n",
    "    # Step 3: Save the model locally\n",
    "    model_path = '/tmp/xgboost_model.pkl'\n",
    "    joblib.dump(xgb_model, model_path)\n",
    "\n",
    "    # Step 4: Register the model in Hopsworks Model Registry\n",
    "    model = mr.sklearn.create_model(\n",
    "        name=\"XGBoost_Model\",\n",
    "        version=1,  # Version of the model\n",
    "        metrics={\"train_score\": train_accuracy, \"validation_score\": accuracy},\n",
    "        description=\"XGBoost Model for Truck Delay Classification\"\n",
    "    )\n",
    "\n",
    "    # Save the model to the registry\n",
    "    model.save(model_path)\n",
    "\n",
    "    print(\"XGBoost model saved and registered in Hopsworks successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameter tuning - XG Boost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tuned_XGBoost with model registry and mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "XGBoost Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.92      0.87       813\n",
      "           1       0.80      0.59      0.68       413\n",
      "\n",
      "    accuracy                           0.81      1226\n",
      "   macro avg       0.81      0.76      0.77      1226\n",
      "weighted avg       0.81      0.81      0.80      1226\n",
      "\n",
      "Validation/Test Accuracy: 0.8116\n",
      "Train Accuracy: 0.9999\n",
      "2024-10-19 20:26:49,871 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14d8ec475814a69a9ce68e8ddc7b755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: 1a27a7639fe7415bbddaae9e47b794f5\n",
      "MLflow Link: http://127.0.0.1:5000/#/experiments/0/runs/1a27a7639fe7415bbddaae9e47b794f5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42370ee106c4cb9883bdc1da0cd9238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ce341c6bf14c8d97d02e9331cf35f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading: 0.000%|          | 0/2691337 elapsed<00:00 remaining<?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/19 20:27:03 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run judicious-kit-471 at: http://127.0.0.1:5000/#/experiments/0/runs/1a27a7639fe7415bbddaae9e47b794f5.\n",
      "2024/10/19 20:27:03 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created, explore it at https://c.app.hopsworks.ai:443/p/1104021/models/Tuned_XGBoost_Model/1\n",
      "Tuned XGBoost model saved and registered in Hopsworks successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import hsml\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Step 1: Establish a connection to Hopsworks using host, project name, and API key\n",
    "connection = hsml.connection(\n",
    "    host=\"c.app.hopsworks.ai\",  # Your Hopsworks instance URL\n",
    "    project=\"ML_truckdelay\",  # Correct project name from Hopsworks\n",
    "    api_key_value=\"8ViXMBkcrCAUFm4Y.PEDm3J6NPoMDtf2L7MpnYsCdElsDMCPRr1RI3vbPtLnjogWE1f6hdKOoxpQbxrM0\"\n",
    ")\n",
    "\n",
    "# Access the model registry\n",
    "mr = connection.get_model_registry()\n",
    "\n",
    "# Set MLflow tracking URI (update if MLflow is hosted remotely)\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "# Step 2: Define the parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # Number of trees\n",
    "    'max_depth': [None, 10, 20],  # Maximum depth of trees\n",
    "    'learning_rate': [0.01, 0.1, 0.2],  # Learning rate\n",
    "    'subsample': [0.8, 1.0],  # Subsample ratio\n",
    "    'colsample_bytree': [0.8, 1.0]  # Subsample ratio of columns\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost model\n",
    "xgb_model = XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Initialize GridSearchCV with 5-fold cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, \n",
    "                           cv=5, n_jobs=-1, scoring='accuracy', \n",
    "                           error_score='raise')\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Fit the grid search to the training data\n",
    "    grid_search.fit(X_train_transformed, y_train)\n",
    "\n",
    "    # Get the best model and hyperparameters\n",
    "    best_xgb_model = grid_search.best_estimator_\n",
    "    best_params = grid_search.best_params_\n",
    "\n",
    "    # Log the best hyperparameters\n",
    "    mlflow.log_params(best_params)\n",
    "\n",
    "    # Make predictions on the validation set\n",
    "    y_pred_xgb = best_xgb_model.predict(X_valid_transformed)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(\"XGBoost Classification Report:\")\n",
    "    print(classification_report(y_valid, y_pred_xgb))\n",
    "    \n",
    "    # Calculate accuracy and other metrics\n",
    "    accuracy = accuracy_score(y_valid, y_pred_xgb)\n",
    "    precision = precision_score(y_valid, y_pred_xgb, average='weighted')\n",
    "    recall = recall_score(y_valid, y_pred_xgb, average='weighted')\n",
    "    f1 = f1_score(y_valid, y_pred_xgb, average='weighted')\n",
    "\n",
    "    print(f\"Validation/Test Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Calculate and log train score\n",
    "    train_predictions = best_xgb_model.predict(X_train_transformed)\n",
    "    train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "    print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "\n",
    "    # Log model, parameters, and metrics in MLflow\n",
    "    input_example = X_valid_transformed[0:1]  # Use one row from your validation set as an example\n",
    "    mlflow.sklearn.log_model(best_xgb_model, \"XGBoost_Tuned_Model\", input_example=input_example)  # Add input example\n",
    "\n",
    "    # Log the metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"test_accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "    })\n",
    "\n",
    "    # Get the run ID for this run\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id\n",
    "\n",
    "    # Display MLflow link to the run\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "    print(f\"MLflow Link: http://127.0.0.1:5000/#/experiments/{experiment_id}/runs/{run_id}\")\n",
    "\n",
    "    # Step 3: Save the model locally\n",
    "    model_path = '/tmp/tuned_xgboost_model.pkl'\n",
    "    joblib.dump(best_xgb_model, model_path)\n",
    "\n",
    "    # Step 4: Register the model in Hopsworks Model Registry\n",
    "    model = mr.sklearn.create_model(\n",
    "        name=\"Tuned_XGBoost_Model\",\n",
    "        version=1,  # Version of the model\n",
    "        metrics={\"train_score\": train_accuracy, \"validation_score\": accuracy},\n",
    "        description=\"Tuned XGBoost Model for Truck Delay Classification\"\n",
    "    )\n",
    "\n",
    "    # Save the model to the registry\n",
    "    model.save(model_path)\n",
    "\n",
    "    print(\"Tuned XGBoost model saved and registered in Hopsworks successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stacking ensemble method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Initialization and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "# Assuming X_train_transformed, y_train, X_valid_transformed, y_valid are already defined\n",
    "\n",
    "# Initialize base models\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "xgboost = XGBClassifier(eval_metric='logloss')\n",
    "\n",
    "# Train base models and obtain predictions\n",
    "log_reg_preds = logistic_regression.fit(X_train_transformed, y_train).predict(X_train_transformed)\n",
    "rf_preds = random_forest.fit(X_train_transformed, y_train).predict(X_train_transformed)\n",
    "xgb_preds = xgboost.fit(X_train_transformed, y_train).predict(X_train_transformed)\n",
    "\n",
    "# Combine base model predictions into a single DataFrame for training the meta-model\n",
    "base_model_preds = np.column_stack((log_reg_preds, rf_preds, xgb_preds))\n",
    "\n",
    "# For validation predictions\n",
    "log_reg_preds_valid = logistic_regression.predict(X_valid_transformed)\n",
    "rf_preds_valid = random_forest.predict(X_valid_transformed)\n",
    "xgb_preds_valid = xgboost.predict(X_valid_transformed)\n",
    "\n",
    "# Combine validation predictions into a single DataFrame for the meta-model\n",
    "base_model_preds_valid = np.column_stack((log_reg_preds_valid, rf_preds_valid, xgb_preds_valid))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meta-Model Initialization, Training, and Logging - using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-Model (Logistic Regression) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       813\n",
      "           1       0.78      0.58      0.66       413\n",
      "\n",
      "    accuracy                           0.80      1226\n",
      "   macro avg       0.79      0.75      0.76      1226\n",
      "weighted avg       0.80      0.80      0.79      1226\n",
      "\n",
      "Meta-Model Accuracy: 0.8010\n",
      "2024-10-18 15:01:10,886 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 15:01:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/18 15:01:13 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run serious-fish-850 at: http://127.0.0.1:5000/#/experiments/0/runs/fd54ac89635946ba9412417860e3aad2.\n",
      "2024/10/18 15:01:13 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: fd54ac89635946ba9412417860e3aad2\n",
      "MLflow Link: http://127.0.0.1:5000/#/experiments/0/runs/fd54ac89635946ba9412417860e3aad2\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the meta-model (e.g., Logistic Regression)\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# Fit the meta-model on the base model predictions\n",
    "meta_model.fit(base_model_preds, y_train)\n",
    "\n",
    "# Make predictions on the validation set using the meta-model\n",
    "y_pred_meta = meta_model.predict(base_model_preds_valid)\n",
    "\n",
    "# Evaluate the meta-model\n",
    "print(\"Meta-Model (Logistic Regression) Classification Report:\")\n",
    "print(classification_report(y_valid, y_pred_meta))\n",
    "print(f\"Meta-Model Accuracy: {accuracy_score(y_valid, y_pred_meta):.4f}\")\n",
    "\n",
    "# Calculate and log the training accuracy\n",
    "train_preds_meta = meta_model.predict(base_model_preds)\n",
    "train_accuracy = accuracy_score(y_train, train_preds_meta)\n",
    "\n",
    "# Start a nested run\n",
    "with mlflow.start_run(nested=True) as run:\n",
    "    # Log the meta-model\n",
    "    mlflow.sklearn.log_model(meta_model, \"Meta_Model_Classifier\")\n",
    "    mlflow.log_params({\"model\": \"Logistic Regression Meta-Model\"})\n",
    "    mlflow.log_metric(\"meta_model_accuracy\", accuracy_score(y_valid, y_pred_meta))\n",
    "    mlflow.log_metric(\"meta_model_train_accuracy\", train_accuracy)  # Log train accuracy\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id\n",
    "\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "    print(f\"MLflow Link: http://127.0.0.1:5000/#/experiments/{experiment_id}/runs/{run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Random Forest as Meta-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-Model (Random Forest) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       813\n",
      "           1       0.78      0.58      0.66       413\n",
      "\n",
      "    accuracy                           0.80      1226\n",
      "   macro avg       0.79      0.75      0.76      1226\n",
      "weighted avg       0.80      0.80      0.79      1226\n",
      "\n",
      "Meta-Model Accuracy: 0.8010\n",
      "2024-10-18 15:02:44,958 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 15:02:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/18 15:02:47 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run upset-fly-476 at: http://127.0.0.1:5000/#/experiments/0/runs/b8e0bcca827a453785502517b2bce9ef.\n",
      "2024/10/18 15:02:47 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: b8e0bcca827a453785502517b2bce9ef\n",
      "MLflow Link: http://127.0.0.1:5000/#/experiments/0/runs/b8e0bcca827a453785502517b2bce9ef\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the meta-model (Random Forest)\n",
    "meta_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the meta-model on the base model predictions\n",
    "meta_model.fit(base_model_preds, y_train)\n",
    "\n",
    "# Make predictions on the validation set using the meta-model\n",
    "y_pred_meta = meta_model.predict(base_model_preds_valid)\n",
    "\n",
    "# Evaluate the meta-model\n",
    "print(\"Meta-Model (Random Forest) Classification Report:\")\n",
    "print(classification_report(y_valid, y_pred_meta))\n",
    "print(f\"Meta-Model Accuracy: {accuracy_score(y_valid, y_pred_meta):.4f}\")\n",
    "\n",
    "# Calculate and log the training accuracy\n",
    "train_preds_meta = meta_model.predict(base_model_preds)\n",
    "train_accuracy = accuracy_score(y_train, train_preds_meta)\n",
    "\n",
    "# Start a nested run\n",
    "with mlflow.start_run(nested=True) as run:\n",
    "    # Log the meta-model\n",
    "    mlflow.sklearn.log_model(meta_model, \"Meta_Model_Classifier_RF\")\n",
    "    mlflow.log_params({\"model\": \"Random Forest Meta-Model\"})\n",
    "    mlflow.log_metric(\"meta_model_accuracy\", accuracy_score(y_valid, y_pred_meta))\n",
    "    mlflow.log_metric(\"meta_model_train_accuracy\", train_accuracy)  # Log train accuracy\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id\n",
    "\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "    print(f\"MLflow Link: http://127.0.0.1:5000/#/experiments/{experiment_id}/runs/{run_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using XGBoost as Meta-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta-Model (XGBoost) Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.86       813\n",
      "           1       0.78      0.58      0.66       413\n",
      "\n",
      "    accuracy                           0.80      1226\n",
      "   macro avg       0.79      0.75      0.76      1226\n",
      "weighted avg       0.80      0.80      0.79      1226\n",
      "\n",
      "Meta-Model Accuracy: 0.8010\n",
      "2024-10-18 15:03:21,937 WARNING: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/18 15:03:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/18 15:03:24 INFO mlflow.tracking._tracking_service.client: ðŸƒ View run delightful-gnat-382 at: http://127.0.0.1:5000/#/experiments/0/runs/94633cf22c6f426b90794159688742d8.\n",
      "2024/10/18 15:03:24 INFO mlflow.tracking._tracking_service.client: ðŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: 94633cf22c6f426b90794159688742d8\n",
      "MLflow Link: http://127.0.0.1:5000/#/experiments/0/runs/94633cf22c6f426b90794159688742d8\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the meta-model (XGBoost)\n",
    "meta_model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "\n",
    "# Fit the meta-model on the base model predictions\n",
    "meta_model.fit(base_model_preds, y_train)\n",
    "\n",
    "# Make predictions on the validation set using the meta-model\n",
    "y_pred_meta = meta_model.predict(base_model_preds_valid)\n",
    "\n",
    "# Evaluate the meta-model\n",
    "print(\"Meta-Model (XGBoost) Classification Report:\")\n",
    "print(classification_report(y_valid, y_pred_meta))\n",
    "print(f\"Meta-Model Accuracy: {accuracy_score(y_valid, y_pred_meta):.4f}\")\n",
    "\n",
    "# Calculate and log the training accuracy\n",
    "train_preds_meta = meta_model.predict(base_model_preds)\n",
    "train_accuracy = accuracy_score(y_train, train_preds_meta)\n",
    "\n",
    "# Start a nested run\n",
    "with mlflow.start_run(nested=True) as run:\n",
    "    # Log the meta-model\n",
    "    mlflow.sklearn.log_model(meta_model, \"Meta_Model_Classifier_XGB\")\n",
    "    mlflow.log_params({\"model\": \"XGBoost Meta-Model\"})\n",
    "    mlflow.log_metric(\"meta_model_accuracy\", accuracy_score(y_valid, y_pred_meta))\n",
    "    mlflow.log_metric(\"meta_model_train_accuracy\", train_accuracy)  # Log train accuracy\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "    experiment_id = run.info.experiment_id\n",
    "\n",
    "    print(f\"MLflow Run ID: {run_id}\")\n",
    "    print(f\"MLflow Link: http://127.0.0.1:5000/#/experiments/{experiment_id}/runs/{run_id}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
